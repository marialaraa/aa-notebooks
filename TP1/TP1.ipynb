{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 1 \n",
    "### Clasificación sobre datos simulados. \n",
    "\n",
    "## Introducción\n",
    "Para este trabajo, hemos creado una función generadora de minions. Sobre cada minion, hemos medido 200 características que representan habilidades que poseen en distintas tareas (relacionadas al Mal).  \n",
    "\n",
    "El doctor Nefario ha ideado una fórmula para determinar si un minion es o no apto para concretar su plan para conquistar el mundo. De esta manera ha etiquetado más de 500 minions. Lamentablemente, ha perdido dicha fórmula y necesita seguir decidiendo si nuevos minions son o no aptos para su macabro plan.\n",
    "\n",
    "Es por esto que nuestro objetivo será construir clasificadores que estimen lo mejor posible la probabilidad de que nuevos minions sean o no aptos para concretar el plan de conquista y así facilitarle las cosas al doctor Nefario.\n",
    "\n",
    "Por otra parte, ya que el doctor Nefario tuvo problemas con equipos que sobreestiman sus resultados, decidió guardarse varias etiquetas extra que no compartirá con nadie, y que luego utilizará para elegir al mejor equipo, al cual contratará para (de una vez por todas) conquistar el mundo. \n",
    "\n",
    "\n",
    "En concreto:\n",
    "\n",
    "Tendrán disponible una matriz de datos $X$ de $500$ filas en donde cada fila $x^{(i)}$ representa un vector de $200$ características de cada instancia. Es decir, $\\textbf{x}^{(i)} = x_1^{(i)}, \\dots, x_{200}^{(i)}$ con $i$ entre $1$ y $500$. Además, tendrán y, un vector de $500$ posiciones con dos posibles valores: $True$ y $False$. \n",
    "\n",
    "Por otra parte, tendrán disponibles más instancias de evaluación $X_{competencia}$ sin las respectivas etiquetas que utilizaremos para evaluar sus resultados. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREAMBULOS\n",
    "%matplotlib inline\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from IPython.display import display, HTML\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as  pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "pd.set_option('precision', 4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.ensemble\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.svm\n",
    "\n",
    "import sklearn.model_selection\n",
    "from numpy.core.umath_tests import inner1d\n",
    "\n",
    "from scipy.stats import randint as sp_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4914</td>\n",
       "      <td>0.1644</td>\n",
       "      <td>1.2315</td>\n",
       "      <td>1.2429</td>\n",
       "      <td>1.5576</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.1983</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>1.5375</td>\n",
       "      <td>-0.7727</td>\n",
       "      <td>-0.1401</td>\n",
       "      <td>2.0871</td>\n",
       "      <td>-0.8312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.2749</td>\n",
       "      <td>0.2780</td>\n",
       "      <td>-1.3108</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>-0.5503</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>-0.4478</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2190</td>\n",
       "      <td>-0.3190</td>\n",
       "      <td>-0.6446</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>-1.2374</td>\n",
       "      <td>-1.3291</td>\n",
       "      <td>-1.3265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.2243</td>\n",
       "      <td>-0.5710</td>\n",
       "      <td>-0.2712</td>\n",
       "      <td>-0.1328</td>\n",
       "      <td>-1.0045</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>-1.4507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>-0.1989</td>\n",
       "      <td>-0.0393</td>\n",
       "      <td>-0.5866</td>\n",
       "      <td>2.2507</td>\n",
       "      <td>1.4925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5853</td>\n",
       "      <td>-0.8532</td>\n",
       "      <td>-0.2723</td>\n",
       "      <td>-0.5493</td>\n",
       "      <td>-2.9824</td>\n",
       "      <td>-0.1697</td>\n",
       "      <td>-0.0430</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6488</td>\n",
       "      <td>-0.7363</td>\n",
       "      <td>-0.8866</td>\n",
       "      <td>-1.2717</td>\n",
       "      <td>-0.1493</td>\n",
       "      <td>0.2007</td>\n",
       "      <td>-1.4820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.4155</td>\n",
       "      <td>1.4187</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>-0.7993</td>\n",
       "      <td>0.2939</td>\n",
       "      <td>-0.1796</td>\n",
       "      <td>-0.7140</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1314</td>\n",
       "      <td>-0.4230</td>\n",
       "      <td>-0.2685</td>\n",
       "      <td>0.3045</td>\n",
       "      <td>-1.2245</td>\n",
       "      <td>-1.9421</td>\n",
       "      <td>1.5186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.2516</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>-1.1980</td>\n",
       "      <td>0.4577</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.2476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5829</td>\n",
       "      <td>-0.5494</td>\n",
       "      <td>0.4607</td>\n",
       "      <td>1.2182</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>3.0034</td>\n",
       "      <td>-0.0344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.6246</td>\n",
       "      <td>-1.0590</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>-1.6657</td>\n",
       "      <td>0.3982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1075</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>-0.4229</td>\n",
       "      <td>0.3977</td>\n",
       "      <td>-0.0808</td>\n",
       "      <td>-1.7054</td>\n",
       "      <td>-0.4786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>-0.9023</td>\n",
       "      <td>-1.7792</td>\n",
       "      <td>-0.0121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8491</td>\n",
       "      <td>0.7469</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>-1.0090</td>\n",
       "      <td>0.3317</td>\n",
       "      <td>-1.7513</td>\n",
       "      <td>-0.5397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>1.7056</td>\n",
       "      <td>0.3418</td>\n",
       "      <td>-0.8350</td>\n",
       "      <td>0.4068</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0130</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>-1.6642</td>\n",
       "      <td>2.5117</td>\n",
       "      <td>-0.0118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.4028</td>\n",
       "      <td>-0.6085</td>\n",
       "      <td>1.0845</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3587</td>\n",
       "      <td>-0.3121</td>\n",
       "      <td>-0.7630</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.6161</td>\n",
       "      <td>-0.0902</td>\n",
       "      <td>-1.0215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1       2       3       4       5       6   ...       193  \\\n",
       "index                                                           ...             \n",
       "0      1.4914  0.1644  1.2315  1.2429  1.5576  0.0455  0.1302   ...   -1.1983   \n",
       "1     -0.2749  0.2780 -1.3108  0.6801 -0.5503  0.6359 -0.4478   ...    1.2190   \n",
       "2     -0.2243 -0.5710 -0.2712 -0.1328 -1.0045  0.9315 -1.4507   ...    0.9459   \n",
       "3      0.5853 -0.8532 -0.2723 -0.5493 -2.9824 -0.1697 -0.0430   ...    1.6488   \n",
       "4     -1.4155  1.4187  0.6027 -0.7993  0.2939 -0.1796 -0.7140   ...    1.1314   \n",
       "...       ...     ...     ...     ...     ...     ...     ...   ...       ...   \n",
       "495    0.2516  0.9375 -1.1980  0.4577  0.9287  0.5373  0.2476   ...    0.5829   \n",
       "496    0.6246 -1.0590  0.9491  0.2687  0.6610 -1.6657  0.3982   ...   -0.1075   \n",
       "497    0.2677  0.1802  0.7154  0.3542 -0.9023 -1.7792 -0.0121   ...    0.8491   \n",
       "498    0.1926  0.7834  1.7056  0.3418 -0.8350  0.4068  0.0495   ...   -0.0130   \n",
       "499    0.0427  0.4028 -0.6085  1.0845  0.1033  0.2698 -0.8598   ...   -0.3587   \n",
       "\n",
       "          194     195     196     197     198     199  \n",
       "index                                                  \n",
       "0     -0.0118  1.5375 -0.7727 -0.1401  2.0871 -0.8312  \n",
       "1     -0.3190 -0.6446 -0.0061 -1.2374 -1.3291 -1.3265  \n",
       "2      0.1430 -0.1989 -0.0393 -0.5866  2.2507  1.4925  \n",
       "3     -0.7363 -0.8866 -1.2717 -0.1493  0.2007 -1.4820  \n",
       "4     -0.4230 -0.2685  0.3045 -1.2245 -1.9421  1.5186  \n",
       "...       ...     ...     ...     ...     ...     ...  \n",
       "495   -0.5494  0.4607  1.2182  0.1025  3.0034 -0.0344  \n",
       "496    0.8993 -0.4229  0.3977 -0.0808 -1.7054 -0.4786  \n",
       "497    0.7469  0.2071 -1.0090  0.3317 -1.7513 -0.5397  \n",
       "498    0.1483  0.5019 -0.0020 -1.6642  2.5117 -0.0118  \n",
       "499   -0.3121 -0.7630  0.6525  0.6161 -0.0902 -1.0215  \n",
       "\n",
       "[500 rows x 200 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       output\n",
       "index        \n",
       "0           0\n",
       "1           0\n",
       "2           0\n",
       "3           0\n",
       "4           1\n",
       "...       ...\n",
       "495         1\n",
       "496         0\n",
       "497         1\n",
       "498         0\n",
       "499         0\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>-0.0103</td>\n",
       "      <td>-0.0436</td>\n",
       "      <td>-0.0208</td>\n",
       "      <td>-0.0571</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0187</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>-0.0356</td>\n",
       "      <td>-0.1940</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>-0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0153</td>\n",
       "      <td>0.9613</td>\n",
       "      <td>1.0360</td>\n",
       "      <td>1.0230</td>\n",
       "      <td>1.0647</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9731</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>1.0075</td>\n",
       "      <td>1.0246</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>0.9819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.1722</td>\n",
       "      <td>-2.4596</td>\n",
       "      <td>-2.8834</td>\n",
       "      <td>-3.7474</td>\n",
       "      <td>-2.9987</td>\n",
       "      <td>-3.2014</td>\n",
       "      <td>-3.6855</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.9110</td>\n",
       "      <td>-2.9642</td>\n",
       "      <td>-2.5163</td>\n",
       "      <td>-3.9278</td>\n",
       "      <td>-2.4254</td>\n",
       "      <td>-2.6234</td>\n",
       "      <td>-2.8690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.6090</td>\n",
       "      <td>-0.6207</td>\n",
       "      <td>-0.7180</td>\n",
       "      <td>-0.6594</td>\n",
       "      <td>-0.7177</td>\n",
       "      <td>-0.6510</td>\n",
       "      <td>-0.7073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6441</td>\n",
       "      <td>-0.6509</td>\n",
       "      <td>-0.6613</td>\n",
       "      <td>-0.8689</td>\n",
       "      <td>-0.6466</td>\n",
       "      <td>-0.6354</td>\n",
       "      <td>-0.6855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0602</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>-0.0713</td>\n",
       "      <td>0.0612</td>\n",
       "      <td>-0.0097</td>\n",
       "      <td>-0.0407</td>\n",
       "      <td>-0.0771</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0473</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>-0.0749</td>\n",
       "      <td>-0.1901</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>-0.0332</td>\n",
       "      <td>-0.0797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.6334</td>\n",
       "      <td>0.7670</td>\n",
       "      <td>0.7066</td>\n",
       "      <td>0.6699</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>0.6508</td>\n",
       "      <td>0.6029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6071</td>\n",
       "      <td>0.6860</td>\n",
       "      <td>0.5743</td>\n",
       "      <td>0.4636</td>\n",
       "      <td>0.7041</td>\n",
       "      <td>0.6575</td>\n",
       "      <td>0.6608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.9702</td>\n",
       "      <td>2.7920</td>\n",
       "      <td>2.6905</td>\n",
       "      <td>2.8091</td>\n",
       "      <td>2.9823</td>\n",
       "      <td>2.9342</td>\n",
       "      <td>3.3240</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0983</td>\n",
       "      <td>3.1469</td>\n",
       "      <td>2.9109</td>\n",
       "      <td>2.4942</td>\n",
       "      <td>3.1804</td>\n",
       "      <td>3.0034</td>\n",
       "      <td>2.5107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "count  500.0000  500.0000  500.0000  500.0000  500.0000  500.0000  500.0000   \n",
       "mean     0.0384    0.0715    0.0056   -0.0103   -0.0436   -0.0208   -0.0571   \n",
       "std      1.0153    0.9613    1.0360    1.0230    1.0647    0.9898    1.0000   \n",
       "min     -3.1722   -2.4596   -2.8834   -3.7474   -2.9987   -3.2014   -3.6855   \n",
       "25%     -0.6090   -0.6207   -0.7180   -0.6594   -0.7177   -0.6510   -0.7073   \n",
       "50%      0.0602    0.0560   -0.0713    0.0612   -0.0097   -0.0407   -0.0771   \n",
       "75%      0.6334    0.7670    0.7066    0.6699    0.6616    0.6508    0.6029   \n",
       "max      2.9702    2.7920    2.6905    2.8091    2.9823    2.9342    3.3240   \n",
       "\n",
       "         ...          193       194       195       196       197       198  \\\n",
       "count    ...     500.0000  500.0000  500.0000  500.0000  500.0000  500.0000   \n",
       "mean     ...      -0.0187    0.0087   -0.0356   -0.1940    0.0250    0.0257   \n",
       "std      ...       0.9731    0.9716    1.0075    1.0246    0.9934    0.9940   \n",
       "min      ...      -2.9110   -2.9642   -2.5163   -3.9278   -2.4254   -2.6234   \n",
       "25%      ...      -0.6441   -0.6509   -0.6613   -0.8689   -0.6466   -0.6354   \n",
       "50%      ...      -0.0473    0.0537   -0.0749   -0.1901    0.0185   -0.0332   \n",
       "75%      ...       0.6071    0.6860    0.5743    0.4636    0.7041    0.6575   \n",
       "max      ...       3.0983    3.1469    2.9109    2.4942    3.1804    3.0034   \n",
       "\n",
       "            199  \n",
       "count  500.0000  \n",
       "mean    -0.0036  \n",
       "std      0.9819  \n",
       "min     -2.8690  \n",
       "25%     -0.6855  \n",
       "50%     -0.0797  \n",
       "75%      0.6608  \n",
       "max      2.5107  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga de datos\n",
    "X = pd.read_csv(\"../TP1/X.csv\", index_col=\"index\")\n",
    "y = pd.read_csv(\"../TP1/y.csv\", index_col=\"index\", dtype=int)  # Cargamos los valores booleanos (True y False)\n",
    "                                                        # como números (1 y 0) para facilitar el manejo luego. \n",
    "    \n",
    "X_competencia = pd.read_csv(\"../TP1/X_competencia1.csv\", index_col=\"index\")\n",
    "y_competencia_ejemplo = pd.read_csv(\"../TP1/y_competencia_ejemplo.csv\", index_col=\"index\")\n",
    "display(X)\n",
    "display(y)\n",
    "X.describe()\n",
    "\n",
    "# Descomentar si quieren ver los datos para la competencia:\n",
    "# display(X_competencia) \n",
    "# display(y_competencia_ejemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "### Separación de datos\n",
    "\n",
    "Contarán con una cantidad limitada de datos, por lo cual es importante tomar una buena decisión en el momento de empezar a utilizarlos. En este punto pedimos que evalúen cómo separar sus datos para desarrollo y para evaluación tomando en cuenta la competencia. No consideramos necesario normalizar los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del total de los datos nos quedamos con un 0.2% como held out que no fue utilizado a lo largo del trabajo práctico. A la hora de la separación tuvimos en cuenta la distribución de los datos para que fuese equivalente en ambos grupos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_dev: (400, 200), y_dev: (400, 1) para desarrollo\n",
      "X_eval: (100, 200), y_eval: (100, 1) para evaluación\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAADFCAYAAAAhb/tIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a788f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EJERCICIO 1. \n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "########################################################\n",
    "import sklearn.model_selection\n",
    "\n",
    "X_dev, X_eval, y_dev, y_eval = sklearn.model_selection.train_test_split(X, y, random_state=SEED, test_size=0.2)\n",
    "\n",
    "# Objetivo: variables X_dev, X_eval, y_dev e y_eval asignadas\n",
    "#########################################################\n",
    "\n",
    "\n",
    "print(\"X_dev: {}, y_dev: {} para desarrollo\".format(X_dev.shape, y_dev.shape))\n",
    "print(\"X_eval: {}, y_eval: {} para evaluación\".format(X_eval.shape, y_eval.shape))\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(np.array(y_dev))  # muestra un histograma para la distribución de y.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "### Construcción de modelos\n",
    "\n",
    "Para este punto, la tarea consiste en construir y evaluar modelos de tipo árbol de decisión, de manera de obtener una estimación realista de la performance de los mismos. \n",
    "\n",
    "1. Entrenar un árbol de decisión con altura máxima 3 y el resto de los hiperparámetros en default. \n",
    "2. Estimar la performance del modelo utilizando K-fold cross validation con K = 5, con las métricas “Accuracy” y “ROC AUC”. Para ello, se pide medir la performance en cada partición tanto sobre el fold de validación como sobre los folds de entrenamiento. Luego, completar la primera tabla.\n",
    "3. Entrenar árboles de decisión para cada una de las siguientes combinaciones y completar la segunda tabla.\n",
    "\n",
    "----\n",
    "\n",
    "**EJERCICIO EXTRA**: Usar la implementación de árboles de decisión que realizaron para la guía de ejercicios de la materia. Adaptarla para que cumpla con la interfaz requerida por sklearn, asegurarse de que funcione con variables continuas y reproducir las tablas anteriores.   \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 1 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validación)</th>\n",
       "      <th>AUC ROC (training)</th>\n",
       "      <th>AUC ROC (validación)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Permutación</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8031</td>\n",
       "      <td>0.6125</td>\n",
       "      <td>0.8135</td>\n",
       "      <td>0.6206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8531</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.8539</td>\n",
       "      <td>0.6202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8187</td>\n",
       "      <td>0.6125</td>\n",
       "      <td>0.8247</td>\n",
       "      <td>0.6132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8281</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>0.8198</td>\n",
       "      <td>0.7238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8094</td>\n",
       "      <td>0.5750</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.5816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy (training)  Accuracy (validación)  AUC ROC (training)  \\\n",
       "Permutación                                                                   \n",
       "1                         0.8031                 0.6125              0.8135   \n",
       "2                         0.8531                 0.6250              0.8539   \n",
       "3                         0.8187                 0.6125              0.8247   \n",
       "4                         0.8281                 0.7375              0.8198   \n",
       "5                         0.8094                 0.5750              0.7845   \n",
       "\n",
       "             AUC ROC (validación)  \n",
       "Permutación                        \n",
       "1                          0.6206  \n",
       "2                          0.6202  \n",
       "3                          0.6132  \n",
       "4                          0.7238  \n",
       "5                          0.5816  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAEGCAYAAAAAHm2OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAcqGzL25UArFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0f1d8050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EJERCICIO 2\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Puede serles de utilidad tener a X_dev e y_dev como matrices de numpy directamente:\n",
    "X_dev_np = np.array(X_dev)\n",
    "y_dev_np = np.array(y_dev).ravel()\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "accuracy_train = []\n",
    "accuracy_eval = []\n",
    "AUCROC_train = []\n",
    "AUCROC_eval = []\n",
    "\n",
    "########################################################\n",
    "# (1) y (2)\n",
    "########################################################\n",
    "for dev_index, eval_index in kf.split(X_dev_np):\n",
    "    X_dev_folds  = X_dev_np[dev_index]\n",
    "    X_eval_folds = X_dev_np[eval_index]\n",
    "    y_dev_folds, y_eval_folds = y_dev_np[dev_index], y_dev_np[eval_index]\n",
    "    \n",
    "    tree = DecisionTreeClassifier(max_depth=3)\n",
    "    tree.fit(X_dev_folds, y_dev_folds)\n",
    "    \n",
    "    prediction_dev = tree.predict(X_dev_folds)\n",
    "    prediction_eval = tree.predict(X_eval_folds)\n",
    "    \n",
    "    accuracy_train.append(accuracy_score(y_dev_folds, prediction_dev))\n",
    "    accuracy_eval.append(accuracy_score(y_eval_folds, prediction_eval))\n",
    "    AUCROC_train.append(roc_auc_score(y_dev_folds, prediction_dev))\n",
    "    AUCROC_eval.append(roc_auc_score(y_eval_folds, prediction_eval))\n",
    "    \n",
    "## Objetivo: accuracies_training, accuracies_validation, aucs_training y aucs_validation asignados\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(1,6))\n",
    "df.index.name = \"Permutación\"\n",
    "                  \n",
    "df[\"Accuracy (training)\"] = accuracy_train   \n",
    "df[\"Accuracy (validación)\"] = accuracy_eval  \n",
    "df[\"AUC ROC (training)\"] = AUCROC_train      \n",
    "df[\"AUC ROC (validación)\"] = AUCROC_eval    \n",
    "\n",
    "\n",
    "display(HTML(\"<h3> TABLA 1 </h3>\"))\n",
    "display(df)\n",
    "\n",
    "# Descomentar las siguientes líneas para graficar el resultado\n",
    "df.plot(kind=\"bar\")\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aclalración: dividimos el X_dev definido inicialmente resultado de la separación del held-out en un set llamado train y otro llamado test para el entrenamiento de los próximos modelos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_dev, y_dev, random_state=SEED, test_size=0.2)\n",
    "\n",
    "\n",
    "X_train_np = np.array(X_train)\n",
    "y_train_np = np.array(y_train).ravel()\n",
    "X_test_np  = np.array(X_test)\n",
    "y_test_np  = np.array(y_test).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 2 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altura máxima</th>\n",
       "      <th>Criterio de evaluación de corte</th>\n",
       "      <th>AUC ROC promedio (training)</th>\n",
       "      <th>AUC ROC promedio (validación)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.8414</td>\n",
       "      <td>0.6927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.6823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Gini</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.7993</td>\n",
       "      <td>0.6562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.9275</td>\n",
       "      <td>0.6354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Altura máxima Criterio de evaluación de corte  AUC ROC promedio (training)  \\\n",
       "0             3                            Gini                       0.8414   \n",
       "1             5                            Gini                       0.9480   \n",
       "2     Inifinito                            Gini                       1.0000   \n",
       "3             3         Ganancia de Información                       0.7993   \n",
       "4             5         Ganancia de Información                       0.9275   \n",
       "5     Inifinito         Ganancia de Información                       1.0000   \n",
       "\n",
       "   AUC ROC promedio (validación)  \n",
       "0                         0.6927  \n",
       "1                         0.6823  \n",
       "2                         0.6562  \n",
       "3                         0.6562  \n",
       "4                         0.6354  \n",
       "5                         0.6250  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################################################\n",
    "# (3)\n",
    "########################################################\n",
    "\n",
    "resultados_training = []\n",
    "resultados_validation = []\n",
    "\n",
    "for criterio in [\"gini\", \"entropy\"]:\n",
    "     for altura in [3, 5, None]:\n",
    "        tree = DecisionTreeClassifier(max_depth=altura, criterion=criterio, random_state=SEED)\n",
    "        tree.fit(X_train, y_train)\n",
    "        \n",
    "        prediction_dev  = tree.predict(X_train)\n",
    "        prediction_eval = tree.predict(X_test)\n",
    "        \n",
    "        resultados_training.append(roc_auc_score(y_train, prediction_dev))\n",
    "        resultados_validation.append(roc_auc_score(y_test, prediction_eval))\n",
    "\n",
    "df = pd.DataFrame(index=range(0,6))\n",
    "\n",
    "df[\"Altura máxima\"] = [3, 5, \"Inifinito\"] * 2\n",
    "df[\"Criterio de evaluación de corte\"] = [\"Gini\"] * 3 + [\"Ganancia de Información\"] * 3\n",
    "df[\"AUC ROC promedio (training)\"] = resultados_training # reemplazar por resultados_training\n",
    "df[\"AUC ROC promedio (validación)\"] = resultados_validation # reemplazar por resultados_validation\n",
    "\n",
    "   \n",
    "display(HTML(\"<h3> TABLA 2 </h3>\"))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Non-ASCII character '\\xc3' in file my_arbol.py on line 7, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details (my_arbol.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"my_arbol.py\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    # ALGORITMO RECURSIVO para construcción de un árbol de decisión binario.\u001b[0m\n\u001b[0m                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Non-ASCII character '\\xc3' in file my_arbol.py on line 7, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details\n"
     ]
    }
   ],
   "source": [
    "import my_arbol as my_tree\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "accuracy_train = []\n",
    "accuracy_eval = []\n",
    "AUCROC_train = []\n",
    "AUCROC_eval = []\n",
    "\n",
    "########################################################\n",
    "# (EE 1) y (EE 2)\n",
    "# El clasificador casero es lento porque prueba todos los\n",
    "# posibles valores para encontrar el corte\n",
    "# O sea, prueba cortar en cada una de las instancias\n",
    "\n",
    "# FALTAAAA: ver si es necesario implementar giny|entropy\n",
    "#           max_depth y critiria ponerlo en la construccion no en el fit\n",
    "########################################################\n",
    "\n",
    "for dev_index, eval_index in kf.split(X_dev):\n",
    "    X_dev_folds = X_dev_np[dev_index]\n",
    "    X_eval_folds = X_dev_np[eval_index]\n",
    "    y_dev_folds, y_eval_folds = y_dev_np[dev_index], y_dev_np[eval_index]\n",
    "    \n",
    "    tree = my_tree.MiClasificadorArbol(list(X.columns))\n",
    "    tree.fit(X_dev_folds, y_dev_folds, 3)\n",
    "    \n",
    "    prediction_dev = tree.predict(X_dev_folds)\n",
    "    prediction_eval = tree.predict(X_eval_folds)\n",
    "    \n",
    "    accuracy_train.append(accuracy_score(y_dev_folds, prediction_dev))\n",
    "    accuracy_eval.append(accuracy_score(y_eval_folds, prediction_eval))\n",
    "    AUCROC_train.append(roc_auc_score(y_dev_folds, prediction_dev))\n",
    "    AUCROC_eval.append(roc_auc_score(y_eval_folds, prediction_eval))\n",
    "    \n",
    "## Objetivo: accuracies_training, accuracies_validation, aucs_training y aucs_validation asignados\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(1,6))\n",
    "df.index.name = \"Permutación\"\n",
    "                  \n",
    "df[\"Accuracy (training)\"] = accuracy_train    # cambiar por accuracies_training\n",
    "df[\"Accuracy (validación)\"] = accuracy_eval   # cambiar por accuracies_validation\n",
    "df[\"AUC ROC (training)\"] = AUCROC_train      # cambiar por aucs_training\n",
    "df[\"AUC ROC (validación)\"] = AUCROC_eval    # cambiar por aucs_validation\n",
    "\n",
    "\n",
    "display(HTML(\"<h3> TABLA 1 </h3>\"))\n",
    "display(df)\n",
    "\n",
    "# Descomentar las siguientes líneas para graficar el resultado\n",
    "df.plot(kind=\"bar\")\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8ced659f9a73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#tree.fit(X_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMiClasificadorArbol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maltura\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_tree' is not defined"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# (EE 3)\n",
    "########################################################\n",
    "\n",
    "resultados_training = []\n",
    "resultados_validation = []\n",
    "\n",
    "#for criterio in [\"gini\", \"entropy\"]:\n",
    "for altura in [3, 5, None]:\n",
    "    #tree = DecisionTreeClassifier(max_depth=altura, criterion=criterio, random_state=SEED)\n",
    "    #tree.fit(X_train, y_train)\n",
    "\n",
    "    tree = my_tree.MiClasificadorArbol(list(X.columns))\n",
    "    tree.fit(X_dev_folds, y_dev_folds, altura)\n",
    "\n",
    "    prediction_dev  = tree.predict(X_train)\n",
    "    prediction_eval = tree.predict(X_test)\n",
    "\n",
    "    resultados_training.append(roc_auc_score(y_train, prediction_dev))\n",
    "    resultados_validation.append(roc_auc_score(y_test, prediction_eval))\n",
    "\n",
    "df = pd.DataFrame(index=range(0,6))\n",
    "\n",
    "df[\"Altura máxima\"] = [3, 5, \"Inifinito\"] * 2\n",
    "df[\"Criterio de evaluación de corte\"] = [\"Gini\"] * 3 + [\"Ganancia de Información\"] * 3\n",
    "df[\"AUC ROC promedio (training)\"] = resultados_training # reemplazar por resultados_training\n",
    "df[\"AUC ROC promedio (validación)\"] = resultados_validation # reemplazar por resultados_validation\n",
    "\n",
    "   \n",
    "display(HTML(\"<h3> TABLA 2 </h3>\"))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Comparación de algoritmos\n",
    "\n",
    "\n",
    "Se pide explorar distintas combinaciones de algoritmos de aprendizaje e hiperparámetros, de manera de buscar una performance óptima. Para este ejercicio es necesario que evalúen posibilidades utilizando la técnica de Grid Search. Como métrica de performance, usar siempre el área bajo la curva (AUC ROC) resultante de 5-fold cross-validation. \n",
    "\n",
    "Algoritmos a probar: KNN, árboles de decisión, LDA, Naive Bayes y SVM. Hiperparámetros: Revisar la documentación de cada uno para la búsqueda de combinaciones prometedoras.  \n",
    "\n",
    "Se pide generar un reporte que contenga: \n",
    "\n",
    "1. Una descripción de las distintas combinaciones consideradas y su performance asociada (las que consideren relevantes, con al menos la mejor combinación para cada algoritmo). \n",
    "\n",
    "1. Una breve explicación de los factores que creen que produjeron dicho resultado. \n",
    "\n",
    "En este punto evaluaremos tanto los hiperparámetros elegidos como las conclusiones relacionadas a por qué piensan que ciertos algoritmos funcionan mejor que otros para estos datos. \n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "**EJERCICIO EXTRA**: Utilizar RandomizedSearchCV con rangos de parámetros que contengan a los utilizados en el GridSearch. Analizar si se encontraron mejores combinaciones de parámetros que no hayan sido tenidas en cuenta con el GridSearch y cuál fue la diferencia de tiempo de ejecución. \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_resultados(grid, top=5, algorithm_name=''):\n",
    "    ## Si quieren, pueden utilizar esta función para imprimir las mejores combinaciones de su grid\n",
    "    print(algorithm_name)\n",
    "    print(\"Top {} combinaciones\".format(top))\n",
    "    df = pd.DataFrame(grid.cv_results_[\"params\"])\n",
    "    df[\"mean_score_validation\"] = grid.cv_results_[\"mean_test_score\"]\n",
    "    df[\"mean_score_training\"] = grid.cv_results_[\"mean_train_score\"]\n",
    "    display(df.sort_values(by=\"mean_score_validation\", ascending=False).head(top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_np = np.array(X_dev)\n",
    "y_np = np.array(y_dev).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KNeighbors Classifier \n",
    "parameters_knn = {'n_neighbors': [5, 10, 50], 'weights': ('uniform', 'distance'), 'algorithm': ['ball_tree', 'kd_tree', 'brute', 'auto']}\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Linear Discriminant Analysis\n",
    "parameters_lda = {'solver': ['svd', 'lsqr', 'eigen']}\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Decision Tree Classifier\n",
    "parameters_tree = {'criterion': ('gini', 'entropy'), 'splitter': ('random', 'best'), 'max_depth': [None, 3, 50, 100, 150]}\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Gaussian\n",
    "gaussian = GaussianNB()\n",
    "\n",
    "# Linear SVM\n",
    "parameters_svm = {'penalty': ('l2', ), 'loss':('squared_hinge', 'hinge'), 'C':[1, 0.1, 0.01, 0.0001, 0.00001]}\n",
    "svm = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbors Classifier - Grid Search\n",
      "Top 24 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>weights</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.7800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>brute</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.7800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>kd_tree</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kd_tree</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.7800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>brute</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7175</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ball_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7175</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kd_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7175</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kd_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7175</td>\n",
       "      <td>0.8325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>brute</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7175</td>\n",
       "      <td>0.8325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    algorithm  n_neighbors   weights  mean_score_validation  \\\n",
       "23       auto           50  distance                 0.7625   \n",
       "22       auto           50   uniform                 0.7625   \n",
       "16      brute           50   uniform                 0.7625   \n",
       "11    kd_tree           50  distance                 0.7625   \n",
       "10    kd_tree           50   uniform                 0.7625   \n",
       "..        ...          ...       ...                    ...   \n",
       "13      brute            5  distance                 0.7175   \n",
       "1   ball_tree            5  distance                 0.7175   \n",
       "7     kd_tree            5  distance                 0.7175   \n",
       "6     kd_tree            5   uniform                 0.7175   \n",
       "12      brute            5   uniform                 0.7175   \n",
       "\n",
       "    mean_score_training  \n",
       "23               1.0000  \n",
       "22               0.7800  \n",
       "16               0.7800  \n",
       "11               1.0000  \n",
       "10               0.7800  \n",
       "..                  ...  \n",
       "13               1.0000  \n",
       "1                1.0000  \n",
       "7                1.0000  \n",
       "6                0.8325  \n",
       "12               0.8325  \n",
       "\n",
       "[24 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbors Classifier - Randomized Search\n",
      "Top 10 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>weights</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kd_tree</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.7800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ball_tree</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.7800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>brute</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.8069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kd_tree</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.8069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>brute</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.8069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ball_tree</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kd_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7175</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ball_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7175</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>brute</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7175</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   algorithm  n_neighbors   weights  mean_score_validation  \\\n",
       "1    kd_tree           50   uniform                 0.7625   \n",
       "2  ball_tree           50   uniform                 0.7625   \n",
       "7      brute           50  distance                 0.7625   \n",
       "4       auto           10   uniform                 0.7475   \n",
       "5    kd_tree           10   uniform                 0.7475   \n",
       "8      brute           10   uniform                 0.7475   \n",
       "6  ball_tree           10  distance                 0.7375   \n",
       "0    kd_tree            5  distance                 0.7175   \n",
       "3  ball_tree            5  distance                 0.7175   \n",
       "9      brute            5  distance                 0.7175   \n",
       "\n",
       "   mean_score_training  \n",
       "1               0.7800  \n",
       "2               0.7800  \n",
       "7               1.0000  \n",
       "4               0.8069  \n",
       "5               0.8069  \n",
       "8               0.8069  \n",
       "6               1.0000  \n",
       "0               1.0000  \n",
       "3               1.0000  \n",
       "9               1.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = GridSearchCV(knn, parameters_knn, cv=5)\n",
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, 24, 'KNeighbors Classifier - Grid Search')\n",
    "\n",
    "n_iter = 10\n",
    "clf = RandomizedSearchCV(knn, parameters_knn, cv=5, n_iter=n_iter)\n",
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, n_iter, 'KNeighbors Classifier - Randomized Search')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Discriminant Analysis - Grid Search\n",
      "Top 3 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solver</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eigen</td>\n",
       "      <td>0.6925</td>\n",
       "      <td>0.9513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.9794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.9794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  solver  mean_score_validation  mean_score_training\n",
       "2  eigen                 0.6925               0.9513\n",
       "0    svd                 0.6800               0.9794\n",
       "1   lsqr                 0.6800               0.9794"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Discriminant Analysis - Randomized Search\n",
      "Top 1 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solver</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svd</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.9794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  solver  mean_score_validation  mean_score_training\n",
       "0    svd                   0.68               0.9794"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = GridSearchCV(lda, parameters_lda, cv=5)\n",
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, 3, 'Linear Discriminant Analysis - Grid Search')\n",
    "\n",
    "n_iter = 1\n",
    "clf = RandomizedSearchCV(lda, parameters_lda, n_iter, cv=5)\n",
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, n_iter, 'Linear Discriminant Analysis - Randomized Search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier - Grid Search\n",
      "Top 20 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>splitter</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gini</td>\n",
       "      <td>3.0</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6950</td>\n",
       "      <td>0.7769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gini</td>\n",
       "      <td>150.0</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6725</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>entropy</td>\n",
       "      <td>3.0</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6725</td>\n",
       "      <td>0.8025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6650</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6275</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gini</td>\n",
       "      <td>50.0</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gini</td>\n",
       "      <td>150.0</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gini</td>\n",
       "      <td>100.0</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gini</td>\n",
       "      <td>100.0</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6125</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion  max_depth splitter  mean_score_validation  mean_score_training\n",
       "2       gini        3.0   random                 0.6950               0.7769\n",
       "10   entropy        NaN   random                 0.6800               1.0000\n",
       "8       gini      150.0   random                 0.6725               1.0000\n",
       "13   entropy        3.0     best                 0.6725               0.8025\n",
       "0       gini        NaN   random                 0.6650               1.0000\n",
       "..       ...        ...      ...                    ...                  ...\n",
       "1       gini        NaN     best                 0.6275               1.0000\n",
       "5       gini       50.0     best                 0.6250               1.0000\n",
       "9       gini      150.0     best                 0.6250               1.0000\n",
       "7       gini      100.0     best                 0.6225               1.0000\n",
       "6       gini      100.0   random                 0.6125               1.0000\n",
       "\n",
       "[20 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier - Randomized Search\n",
      "Top 8 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>splitter</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gini</td>\n",
       "      <td>3.0</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7100</td>\n",
       "      <td>0.7732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entropy</td>\n",
       "      <td>3.0</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>0.8025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6575</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gini</td>\n",
       "      <td>100.0</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entropy</td>\n",
       "      <td>100.0</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6325</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gini</td>\n",
       "      <td>150.0</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6325</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6275</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gini</td>\n",
       "      <td>100.0</td>\n",
       "      <td>best</td>\n",
       "      <td>0.5900</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion  max_depth splitter  mean_score_validation  mean_score_training\n",
       "1      gini        3.0   random                 0.7100               0.7732\n",
       "4   entropy        3.0     best                 0.6700               0.8025\n",
       "5   entropy        NaN     best                 0.6575               1.0000\n",
       "3      gini      100.0   random                 0.6525               1.0000\n",
       "0   entropy      100.0     best                 0.6325               1.0000\n",
       "6      gini      150.0   random                 0.6325               1.0000\n",
       "7   entropy        NaN   random                 0.6275               1.0000\n",
       "2      gini      100.0     best                 0.5900               1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = GridSearchCV(tree, parameters_tree, cv=5)\n",
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, 20, 'Decision Tree Classifier - Grid Search')\n",
    "\n",
    "n_iter = 8\n",
    "clf = RandomizedSearchCV(tree, parameters_tree, n_iter, cv=5)\n",
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, n_iter, 'Decision Tree Classifier - Randomized Search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian\n",
      "Top 1 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>splitter</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entropy</td>\n",
       "      <td>3.0</td>\n",
       "      <td>best</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.8025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion  max_depth splitter  mean_score_validation  mean_score_training\n",
       "4   entropy        3.0     best                   0.67               0.8025"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, 1, 'Gaussian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM - Grid Search\n",
      "Top 10 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>loss</th>\n",
       "      <th>penalty</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0000e-02</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.7575</td>\n",
       "      <td>0.9813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0000e-02</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.7525</td>\n",
       "      <td>0.9263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0000e-01</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0000e-01</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>0.9969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0000e-04</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000e+00</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0000e+00</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0000e-05</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.7250</td>\n",
       "      <td>0.7631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0000e-04</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.7225</td>\n",
       "      <td>0.7563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0000e-05</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.7225</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            C           loss penalty  mean_score_validation  \\\n",
       "4  1.0000e-02  squared_hinge      l2                 0.7575   \n",
       "5  1.0000e-02          hinge      l2                 0.7525   \n",
       "2  1.0000e-01  squared_hinge      l2                 0.7400   \n",
       "3  1.0000e-01          hinge      l2                 0.7400   \n",
       "6  1.0000e-04  squared_hinge      l2                 0.7400   \n",
       "0  1.0000e+00  squared_hinge      l2                 0.7375   \n",
       "1  1.0000e+00          hinge      l2                 0.7375   \n",
       "8  1.0000e-05  squared_hinge      l2                 0.7250   \n",
       "7  1.0000e-04          hinge      l2                 0.7225   \n",
       "9  1.0000e-05          hinge      l2                 0.7225   \n",
       "\n",
       "   mean_score_training  \n",
       "4               0.9813  \n",
       "5               0.9263  \n",
       "2               1.0000  \n",
       "3               0.9969  \n",
       "6               0.8000  \n",
       "0               1.0000  \n",
       "1               1.0000  \n",
       "8               0.7631  \n",
       "7               0.7563  \n",
       "9               0.7556  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM - Randomized Search\n",
      "Top 5 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>loss</th>\n",
       "      <th>penalty</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0000e-02</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.7525</td>\n",
       "      <td>0.9263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000e-01</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0000e-04</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0000e-04</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.7225</td>\n",
       "      <td>0.7563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0000e-05</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.7225</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            C           loss penalty  mean_score_validation  \\\n",
       "1  1.0000e-02          hinge      l2                 0.7525   \n",
       "0  1.0000e-01  squared_hinge      l2                 0.7400   \n",
       "3  1.0000e-04  squared_hinge      l2                 0.7400   \n",
       "2  1.0000e-04          hinge      l2                 0.7225   \n",
       "4  1.0000e-05          hinge      l2                 0.7225   \n",
       "\n",
       "   mean_score_training  \n",
       "1               0.9263  \n",
       "0               1.0000  \n",
       "3               0.8000  \n",
       "2               0.7563  \n",
       "4               0.7556  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = GridSearchCV(svm, parameters_svm, cv=5)\n",
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, 10, 'Linear SVM - Grid Search')\n",
    "\n",
    "n_iter = 5\n",
    "clf = RandomizedSearchCV(svm, parameters_svm, n_iter, cv=5)\n",
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, n_iter, 'Linear SVM - Randomized Search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Conclusiones Grid Search"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# KNeighbors Classifier \n",
    "\n",
    "Del total de 8 parametros probamos todas las permutaciones de los siguientes tres para distintos valores:\n",
    "\n",
    "- n_neighbors: número de vecinos utilizado por kneighbors query. Que por default es 5. \n",
    "- weights: es la función de peso que se utiliza en la predicción. Tiene como opciones: uniform (todos los puntos del vecindario pesan lo mismo), distance (los vecinos más cercanos tienen más peso) y callable (función definida por el usuario). \n",
    "- algorithm: es el algoritmo utilizado para computar los vecinos más cercanos. Puede ser: ball_tree, kd_tree, brute o \n",
    "auto. \n",
    "\n",
    "No se consideró necesario cambiar las métricas ni hacer un número mayor de trabajos paralelos debido a la cantidad de datos (TODO)\n",
    "\n",
    "Los valores utilizados para n_neighbors fueron 5, 10 y 50. \n",
    "De las opciones de weights se dejó afuera callable por falta de experiencia (TODO)\n",
    "De algorithm se corrieron las opciones ball_tree, kd_tree, brute y auto. Sin parametrizar el leaf_size para ball_tree y kd_tree. \n",
    "\n",
    "Respecto de la performance. Los mejores rendimientos están dados por las combinaciones: auto/brute/kd_tree, 50, uniform. En todas ellas el mean_score_validation es de 0.7625 en relación al mean_score_training de 0.7800. En todas las otras combinaciones el primer valor o bien baja o bien se mantiene, pero sube el segundo hasta 1.000. \n",
    "Pareciera que lo que marca la diferencia es el weight. Siempre mejora con uniform mientras que overfittea con distance bajo las mismas combinaciones de los otros parametros. \n",
    "\n",
    "Quizás podríamos probar fijandole parametros al kd_tree para ver si mejora respecto de bruto o auto. \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis\n",
    "\n",
    "De los seis posibles parametros modificamos solo uno, solver, cuyas opciones son: singular value decomposition (svd) que no computa la matriz de covarianza, least squares solution (lsqr) y eigenvalue decomposition (eigen). Eigen da mejor que los otros dos métodos. En particular tiene el mean_score_validation más alto (0.6925) y el mean_score_training validation más bajo (0.9513).\n",
    "\n",
    "Duda(TODO) sklearn dice que no tiene hiperparametros para tunear. Luego tiene parametros. Y lsqr y eigen se pueden combinar con shrinkage (quizás podríamos modificar eso también) \n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "Del total de 13 parametros probamos todas las permutaciones de los siguientes tres para distintos valores:\n",
    "- criterion: es la función que mide la calidad del split. Las opciones son gini y entropy. \n",
    "- splitter: es la estrategia utilizada para elegir la partición en cada nodo. Puede ser best, para elegir el mejor corte o random que elige el mejor corte random. \n",
    "- max_depth: es la profundidad máxima del árbol. Puede ser seteada como int o como None. Si es None, los nodos se expanden hasta que todas las hojas son puras o hasta que contengan menos muestras que min_samples_split.\n",
    "\n",
    "Los valaores utilizados para criterion fueron entropy y gini.\n",
    "Para splitter, random y best y\n",
    "para maz_depth 3, 50, 100 y None. \n",
    "\n",
    "Respecto de la performance, los mejores rendimientos están dados por las combinaciones gini/3/random con un mean_score_validation de (0.6950) y con un mean_score_training (0.77),  seguido por entropy/3/best con un mean_score_validation (0.6725) de y con un mean_score_training (0.8). Para todos los demás casos, las cominaciones resultan en un mean_score_training de (1.000), es decir, caen en overfitting. La razón parece ser, sobre todo, los valores altos de max_depth en realción a la cantidad de atributos. \n",
    "\n",
    "TODO no se que pasa con gini/3/best o con entropy/3/random como para jutificar el mejor. \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Gaussian\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Linear SVM\n",
    "\n",
    "Del total de 12 parametros probamos todas las permutaciones de los siguientes tres enumerados a continuación. Típicamente, dentro de los hiperparametros a ser modificados en SVM se encuentra el kernell que, en este caso, es lineal por disposición de la consigna. Hecha esta aclaración: \n",
    "\n",
    "- penalty: l1 o l2. Especifica la norma utilizada en la penalización. ls es la estándar en SVC. \n",
    "- loss: puede ser hinge o squared_hinge. Especifica la función de costo. \n",
    "- C: El parametro C es el grado de clasificaciones correctas que se va a pedir a un determinado SVM. Valores de C más grandes resultarán en un hiperplano de margen más pequeño y más pequeños al revés. \n",
    "\n",
    "Los valores utilizados para penalty fueron l1 y l2. Luego de una serie de pruebas l2 fue elegido como unica opción (TODO). \n",
    "Oara loss se utilizo hinge y squared_hinge. \n",
    "C fue variado en varias iteraciones viendo que los valores menores a uno son los que mejor acomodan los datos. Se utilizó: 1, 0.1, 0.01, 0.0001, 0.00001. \n",
    "\n",
    "En lo que respecta a la performance, quizás el mejor rendimiento resulte de un tradeoff entre los valores de mean_score_validation y mean_score_training. Para valores muy chicos del C el primero aumenta, pero también lo hace el segundo hasta el limite del overfitting. \n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Distintos sets de datos pueden ser mejor clasificados por unos u otros algoritmos. En este caso, las performances siguen este orden decreciente: KNN, SVM, DecisionTree, LDA, NB. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 4: \n",
    "### Diagnóstico Sesgo-Varianza. \n",
    "\n",
    "En este punto, se pide inspeccionar dos de sus mejores modelos encontrados hasta ahora: el mejor modelo de tipo árbol de decisión y el mejor de tipo SVM. Para ello:\n",
    "\n",
    "1. Graficar curvas de complejidad para cada modelo, variando la profundidad en el caso de árboles, y el hiperparámetro C en el caso de SVM. Diagnosticar cómo afectan al sesgo y a la varianza esos dos hiperparámetros.\n",
    "2. Graficar curvas de aprendizaje para cada modelo. En base a estas curvas, sacar conclusiones sobre si los algoritmos parecen haber alcanzado su límite, o bien si aumentar la cantidad de datos debería ayudar.\n",
    "3. Construir un modelo RandomForest con 200 árboles. Explorar para qué sirve el hiperparámetro max_features y cómo afecta a la performance del algoritmo mediante una curva de complejidad. Explicar por qué creen que se dieron los resultados obtenidos. Por último, graficar una curva de aprendizaje sobre los parámetros elegidos para determinar si sería útil o no conseguir más datos (usar  grid search para encontrar una buena combinación de parámetros).  \n",
    "\n",
    "\n",
    "**Atención**: Tener en cuenta que debemos seguir utilizando ROC AUC como métrica para estas curvas.\n",
    "\n",
    "**ver**: http://scikit-learn.org/stable/modules/learning_curve.html#learning-curve\n",
    "\n",
    "----\n",
    "**EJERCICIO EXTRA:** Utilizar RandomizedSearchCV para explorar la performance del algoritmo de Gradient Boosting y comparar con los resultados obtenidos en el punto (c).\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCv+9Z2WkRAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0f0fe310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Decision Tree Classifier\n",
    "max_depths = [1, 3, 10, 50, 150, 200]\n",
    "auc_roc = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    tree = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    tree.fit(X_train_np, y_train_np)\n",
    "        \n",
    "    prediction_eval = tree.predict(X_test_np)\n",
    "    auc_roc.append(roc_auc_score(y_test_np, prediction_eval))\n",
    "\n",
    "\n",
    "fig = plt.scatter(max_depths, auc_roc , marker=\".\", color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD8CAYAAACW/ATfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhr0kNcCwl6QGGPaS1ADDXpIa8H9ovO9BNeQcmwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a19909710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Decision Tree Classifier\n",
    "Cs = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1]\n",
    "auc_roc = []\n",
    "\n",
    "for C in Cs:\n",
    "    svm = LinearSVC(C=C)\n",
    "    svm.fit(X_train_np, y_train_np)\n",
    "        \n",
    "    prediction_eval = svm.predict(X_test_np)\n",
    "    auc_roc.append(roc_auc_score(y_test_np, prediction_eval))\n",
    "\n",
    "\n",
    "fig = plt.scatter(auc_roc, Cs, marker=\".\", color=\"red\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Los errores de predicción pueden ser clasificados en errores de sesgo, errores de varianza y errores irreductibles. Los dos primeros pueden ser mejorados. Para hacerlo, se buscará obtener un método de aprendizaje que logre disminuir al mismo tiempo sesgo y varianza. Se entiende por sesgo las suposiciones que los algoritmos hacen para poder estimar la función target que se desee aprender. Por varianza, la cantidad que varía la estimación al cambiar el set de datos de entrenamientos. Lo que suele ocurrir es que métodos más flexibles en cuanto a las suposiciones, es decir, con menor sesgo, resultan en una mayor varianza y,al revés. Se incurre, así, en un problema de trade-off entre sesgo y varianza. \n",
    "\n",
    "En el caso de los Arboles de Decisión, este trade-off depende de la profundidad del arbol, es decir, del parametro max_depth. Un árbol de mayor profundidad hará muy pocas suposiciones sobre los datos y se adaptará muy bien a lo que le sea pasado como entrenamiento, aumentando así la varianza en gran medida al actuar sobre otro set de datos. \n",
    "En caso de los Support Vector Machines, el trade-off depende del parámetro C. Un aumento de este parametro permite hacer más suposiciones sobre los datos achicando el margen del hiperplano (TODO). Esto aumenta el sesgo y por consiguiente reduce la varianza. \n",
    "\n",
    "Para los gráficos obtenidos. En caso de Arbol de Decisión se puede ver...\n",
    "En caso de SVM se puede ver...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Learning Curves (SVM)\"\n",
    "estimator = LinearSVC(C=0.0001)\n",
    "plot_learning_curve(estimator, title, X_dev_np, y_dev_np, ylim=(0.7, 0.95), cv=5, n_jobs=4)\n",
    "\n",
    "title = \"Learning Curves (Decision Tree Classifier)\"\n",
    "estimator = DecisionTreeClassifier(max_depth=3, criterion='entropy', splitter='best')\n",
    "plot_learning_curve(estimator, title, X_dev_np, y_dev_np, (0.6, 1.05), cv=5, n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "La curva de aprendizaje muestra el score de validación y de entrenamiento de un estimador variando el número de las muestras de entrenamiento. Sirve para averiguar cuanto se beneficia el modelo de agregar nueva data de entrenamieno y si el estimador sufre más de error de sesgo o de varianza. \n",
    "Si ambos errores estuvieran presentes ambos scores convergen a un valor demasiado bajo a medida que aumenta el tamaño del set de entrenamiento. En este caso, no se percibrán beneficios de aumentar la data de entrenamiento. \n",
    "En cambio si el score de entrenamiento es más grande que el de validación para el máximo número de muestras de entrenamiento, agregar más muestras mejorará la generalización.  \n",
    "\n",
    "Nuestros gráficos se encuentran en el segundo caso (TODO). No se puede decir mucho más con la cantidad de datos que tenemos. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest Classifier\n",
    "max_features = [5, 50, 100, 183, 'auto', 'log2']\n",
    "auc_roc = []\n",
    "\n",
    "for max_feature in max_features :\n",
    "    random_forest = RandomForestClassifier(n_estimators=200, criterion='entropy', max_depth=3, max_features=max_feature)\n",
    "    random_forest.fit(X_train_np, y_train_np)\n",
    "        \n",
    "    prediction_eval = random_forest.predict(X_test_np)\n",
    "    score = roc_auc_score(y_test_np, prediction_eval)\n",
    "    auc_roc.append(score)\n",
    "\n",
    "\n",
    "fig = plt.scatter(range(len(max_features)), auc_roc, marker=\".\", color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedamos solo con arboles de profundidad tres. Mayor profundidad overfittea. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "parameters_rf = {'n_estimators':(200,), 'criterion': ('gini', 'entropy'), 'max_depth': [3], 'max_features':[5, 50, 100, 183, 'auto', 'log2']}\n",
    "rf = RandomForestClassifier()\n",
    "clf = GridSearchCV(rf, parameters_rf, cv=5)\n",
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, 10, 'Random Forest Classifier - Grid Search')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title = \"Learning Curves (Random Forest)\"\n",
    "estimator = RandomForestClassifier(criterion='entropy', max_depth=3, max_features='auto', n_estimators=200)\n",
    "plot_learning_curve(estimator, title, X_dev_np, y_dev_np, ylim=(0.7, 1.05), cv=5, n_jobs=4)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "El método Random Forest crea una serie de árboles de decisión. Su particularidad reside en que, al momento de hacerlo, cada vez que se considera un split, se elige como candidatos del split de manera random una muestra m de predictores de entre la totalidad del set p. Y de estos m elegidos al azar, el split solo puede elegir uno. Esto hace que una nueva muestra de predictores sea elegida cada vez. \n",
    "\n",
    "max_features determina el número de features considerado al momento de buscar el mejor split. Puede ocurrir: \n",
    "\n",
    "- Si es un int, entonces considera la cantidad max_features de features en cada split. \n",
    "- Si es float, entonces la cantidad max_features es una fracción fraction y se considera int(max_features * n_features) en cada split. \n",
    "- Si es auto, entonces max_features=sqrt(n_features)\n",
    "- Si es sqrt, entonces max_features=sqrt(n_features)\n",
    "- Si es log2, entonces max_features=log2(n_features)\n",
    "- Si es None, entonces max_features=n_features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting Classifier\n",
    "parameters_gb = {'criterion': ('gini', 'entropy'), 'splitter': ('random', 'best'), 'max_depth': [None, 3, 50, 100, 150]}\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "n_iter = 8\n",
    "clf = RandomizedSearchCV(gb, parameters_gb, n_iter, cv=5)\n",
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, n_iter, 'Gradient Boosting Classifier - Randomized Search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competencias\n",
    "\n",
    "La entrega del trabajo estará acompañada de una competencia en la cual deberán poner a prueba su mejor modelo y sobre todo, su capacidad para estimar sus resultados. \n",
    "\n",
    "Su tarea será estimar la performance (AUC ROC) que tendrá su mejor modelo en datos de evaluación (X_competencia). \n",
    "\n",
    "Para ello, deberán predecir las probabilidades de las distintas instancias con su modelo, enviarnos dichas probabilidades junto a una estimación con 4 decimales de cuál será el AUC ROC resultante y calcularemos el resultado real. El grupo que consiga acercarse más al valor real, será el grupo ganador.  \n",
    "\n",
    "Recomendamos no perder de vista esta competencia en el momento de separar los datos en los primeros puntos. \n",
    "\n",
    "Para esto, junto con la entrega del informe, deberán enviar un archivo en formato csv con las columnas “index” y “output” (ver ejemplo de archivo en: [y_competencia_ejemplo.csv](https://github.com/pbrusco/aa-notebooks/blob/master/TP1/y_competencia_ejemplo.csv)) y un valor esperado de AUC ROC. \n",
    "\n",
    "\n",
    "## Entrega\n",
    "- Contarán con un esqueleto en formato Jupyter Notebook en donde tendrán que completar las celdas faltantes (ya sea con explicaciones y gráficos o código). \n",
    "- El notebook final deberá ser entregado en formatos .html e .ipynb. Es necesario que los resultados puedan reproducirse al ejecutar todas las celdas en orden (Kernel - Restart and Run All) utilizando las bibliotecas requeridas en el archivo: requirements.txt del repositorio. \n",
    "- Tienen tiempo hasta las 23:59hs del día miércoles 17/10/2018. La entrega se debe realizar a través del campus virtual y debe contener el informe.\n",
    "- El trabajo deberá elaborarse en grupos de 3 personas.\n",
    "- Se podrán pedir pruebas de integridad y autoría; es decir, verificar que la salida solicitada es fruto del modelo presentado y que el modelo fue construido según lo requerido en este enunciado.\n",
    "- La evaluación será grupal y se basará en la calidad del informe (presentación, claridad, prolijidad); la originalidad, practicidad y coherencia técnica de la solución; la corrección y solidez de las pruebas realizadas.\n",
    "- En el primer parcial se incluirá una pregunta sobre la solución entregada. Esa pregunta no influirá en la nota del parcial, pero sí en la nota individual del TP1.\n",
    "- La participación en la competencia es obligatoria. De todas maneras, el resultado no incidirán en la nota de la materia.\n",
    "- Los ejercicios extra son opcionales para aprobar el TP, pero son obligatorios para promocionar la materia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
