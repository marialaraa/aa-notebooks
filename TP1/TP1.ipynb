{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 1 \n",
    "### Clasificación sobre datos simulados. \n",
    "\n",
    "## Introducción\n",
    "Para este trabajo, hemos creado una función generadora de minions. Sobre cada minion, hemos medido 200 características que representan habilidades que poseen en distintas tareas (relacionadas al Mal).  \n",
    "\n",
    "El doctor Nefario ha ideado una fórmula para determinar si un minion es o no apto para concretar su plan para conquistar el mundo. De esta manera ha etiquetado más de 500 minions. Lamentablemente, ha perdido dicha fórmula y necesita seguir decidiendo si nuevos minions son o no aptos para su macabro plan.\n",
    "\n",
    "Es por esto que nuestro objetivo será construir clasificadores que estimen lo mejor posible la probabilidad de que nuevos minions sean o no aptos para concretar el plan de conquista y así facilitarle las cosas al doctor Nefario.\n",
    "\n",
    "Por otra parte, ya que el doctor Nefario tuvo problemas con equipos que sobreestiman sus resultados, decidió guardarse varias etiquetas extra que no compartirá con nadie, y que luego utilizará para elegir al mejor equipo, al cual contratará para (de una vez por todas) conquistar el mundo. \n",
    "\n",
    "\n",
    "En concreto:\n",
    "\n",
    "Tendrán disponible una matriz de datos $X$ de $500$ filas en donde cada fila $x^{(i)}$ representa un vector de $200$ características de cada instancia. Es decir, $\\textbf{x}^{(i)} = x_1^{(i)}, \\dots, x_{200}^{(i)}$ con $i$ entre $1$ y $500$. Además, tendrán y, un vector de $500$ posiciones con dos posibles valores: $True$ y $False$. \n",
    "\n",
    "Por otra parte, tendrán disponibles más instancias de evaluación $X_{competencia}$ sin las respectivas etiquetas que utilizaremos para evaluar sus resultados. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREAMBULOS\n",
    "%matplotlib inline\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from IPython.display import display, HTML\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as  pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "pd.set_option('precision', 4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.ensemble\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.svm\n",
    "import sklearn.model_selection\n",
    "\n",
    "from numpy.core.umath_tests import inner1d\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "\n",
    "from mi_clasificador_arbol import MiClasificadorArbol\n",
    "from learning_curve import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4914</td>\n",
       "      <td>0.1644</td>\n",
       "      <td>1.2315</td>\n",
       "      <td>1.2429</td>\n",
       "      <td>1.5576</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.1983</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>1.5375</td>\n",
       "      <td>-0.7727</td>\n",
       "      <td>-0.1401</td>\n",
       "      <td>2.0871</td>\n",
       "      <td>-0.8312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.2749</td>\n",
       "      <td>0.2780</td>\n",
       "      <td>-1.3108</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>-0.5503</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>-0.4478</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2190</td>\n",
       "      <td>-0.3190</td>\n",
       "      <td>-0.6446</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>-1.2374</td>\n",
       "      <td>-1.3291</td>\n",
       "      <td>-1.3265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.2243</td>\n",
       "      <td>-0.5710</td>\n",
       "      <td>-0.2712</td>\n",
       "      <td>-0.1328</td>\n",
       "      <td>-1.0045</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>-1.4507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>-0.1989</td>\n",
       "      <td>-0.0393</td>\n",
       "      <td>-0.5866</td>\n",
       "      <td>2.2507</td>\n",
       "      <td>1.4925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5853</td>\n",
       "      <td>-0.8532</td>\n",
       "      <td>-0.2723</td>\n",
       "      <td>-0.5493</td>\n",
       "      <td>-2.9824</td>\n",
       "      <td>-0.1697</td>\n",
       "      <td>-0.0430</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6488</td>\n",
       "      <td>-0.7363</td>\n",
       "      <td>-0.8866</td>\n",
       "      <td>-1.2717</td>\n",
       "      <td>-0.1493</td>\n",
       "      <td>0.2007</td>\n",
       "      <td>-1.4820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.4155</td>\n",
       "      <td>1.4187</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>-0.7993</td>\n",
       "      <td>0.2939</td>\n",
       "      <td>-0.1796</td>\n",
       "      <td>-0.7140</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1314</td>\n",
       "      <td>-0.4230</td>\n",
       "      <td>-0.2685</td>\n",
       "      <td>0.3045</td>\n",
       "      <td>-1.2245</td>\n",
       "      <td>-1.9421</td>\n",
       "      <td>1.5186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.2516</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>-1.1980</td>\n",
       "      <td>0.4577</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.2476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5829</td>\n",
       "      <td>-0.5494</td>\n",
       "      <td>0.4607</td>\n",
       "      <td>1.2182</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>3.0034</td>\n",
       "      <td>-0.0344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.6246</td>\n",
       "      <td>-1.0590</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>-1.6657</td>\n",
       "      <td>0.3982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1075</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>-0.4229</td>\n",
       "      <td>0.3977</td>\n",
       "      <td>-0.0808</td>\n",
       "      <td>-1.7054</td>\n",
       "      <td>-0.4786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>-0.9023</td>\n",
       "      <td>-1.7792</td>\n",
       "      <td>-0.0121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8491</td>\n",
       "      <td>0.7469</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>-1.0090</td>\n",
       "      <td>0.3317</td>\n",
       "      <td>-1.7513</td>\n",
       "      <td>-0.5397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>1.7056</td>\n",
       "      <td>0.3418</td>\n",
       "      <td>-0.8350</td>\n",
       "      <td>0.4068</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0130</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>-1.6642</td>\n",
       "      <td>2.5117</td>\n",
       "      <td>-0.0118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.4028</td>\n",
       "      <td>-0.6085</td>\n",
       "      <td>1.0845</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3587</td>\n",
       "      <td>-0.3121</td>\n",
       "      <td>-0.7630</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.6161</td>\n",
       "      <td>-0.0902</td>\n",
       "      <td>-1.0215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1       2       3       4       5       6   ...       193  \\\n",
       "index                                                           ...             \n",
       "0      1.4914  0.1644  1.2315  1.2429  1.5576  0.0455  0.1302   ...   -1.1983   \n",
       "1     -0.2749  0.2780 -1.3108  0.6801 -0.5503  0.6359 -0.4478   ...    1.2190   \n",
       "2     -0.2243 -0.5710 -0.2712 -0.1328 -1.0045  0.9315 -1.4507   ...    0.9459   \n",
       "3      0.5853 -0.8532 -0.2723 -0.5493 -2.9824 -0.1697 -0.0430   ...    1.6488   \n",
       "4     -1.4155  1.4187  0.6027 -0.7993  0.2939 -0.1796 -0.7140   ...    1.1314   \n",
       "...       ...     ...     ...     ...     ...     ...     ...   ...       ...   \n",
       "495    0.2516  0.9375 -1.1980  0.4577  0.9287  0.5373  0.2476   ...    0.5829   \n",
       "496    0.6246 -1.0590  0.9491  0.2687  0.6610 -1.6657  0.3982   ...   -0.1075   \n",
       "497    0.2677  0.1802  0.7154  0.3542 -0.9023 -1.7792 -0.0121   ...    0.8491   \n",
       "498    0.1926  0.7834  1.7056  0.3418 -0.8350  0.4068  0.0495   ...   -0.0130   \n",
       "499    0.0427  0.4028 -0.6085  1.0845  0.1033  0.2698 -0.8598   ...   -0.3587   \n",
       "\n",
       "          194     195     196     197     198     199  \n",
       "index                                                  \n",
       "0     -0.0118  1.5375 -0.7727 -0.1401  2.0871 -0.8312  \n",
       "1     -0.3190 -0.6446 -0.0061 -1.2374 -1.3291 -1.3265  \n",
       "2      0.1430 -0.1989 -0.0393 -0.5866  2.2507  1.4925  \n",
       "3     -0.7363 -0.8866 -1.2717 -0.1493  0.2007 -1.4820  \n",
       "4     -0.4230 -0.2685  0.3045 -1.2245 -1.9421  1.5186  \n",
       "...       ...     ...     ...     ...     ...     ...  \n",
       "495   -0.5494  0.4607  1.2182  0.1025  3.0034 -0.0344  \n",
       "496    0.8993 -0.4229  0.3977 -0.0808 -1.7054 -0.4786  \n",
       "497    0.7469  0.2071 -1.0090  0.3317 -1.7513 -0.5397  \n",
       "498    0.1483  0.5019 -0.0020 -1.6642  2.5117 -0.0118  \n",
       "499   -0.3121 -0.7630  0.6525  0.6161 -0.0902 -1.0215  \n",
       "\n",
       "[500 rows x 200 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       output\n",
       "index        \n",
       "0           0\n",
       "1           0\n",
       "2           0\n",
       "3           0\n",
       "4           1\n",
       "...       ...\n",
       "495         1\n",
       "496         0\n",
       "497         1\n",
       "498         0\n",
       "499         0\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>500.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>-0.0103</td>\n",
       "      <td>-0.0436</td>\n",
       "      <td>-0.0208</td>\n",
       "      <td>-0.0571</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0187</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>-0.0356</td>\n",
       "      <td>-0.1940</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>-0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0153</td>\n",
       "      <td>0.9613</td>\n",
       "      <td>1.0360</td>\n",
       "      <td>1.0230</td>\n",
       "      <td>1.0647</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9731</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>1.0075</td>\n",
       "      <td>1.0246</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>0.9819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.1722</td>\n",
       "      <td>-2.4596</td>\n",
       "      <td>-2.8834</td>\n",
       "      <td>-3.7474</td>\n",
       "      <td>-2.9987</td>\n",
       "      <td>-3.2014</td>\n",
       "      <td>-3.6855</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.9110</td>\n",
       "      <td>-2.9642</td>\n",
       "      <td>-2.5163</td>\n",
       "      <td>-3.9278</td>\n",
       "      <td>-2.4254</td>\n",
       "      <td>-2.6234</td>\n",
       "      <td>-2.8690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.6090</td>\n",
       "      <td>-0.6207</td>\n",
       "      <td>-0.7180</td>\n",
       "      <td>-0.6594</td>\n",
       "      <td>-0.7177</td>\n",
       "      <td>-0.6510</td>\n",
       "      <td>-0.7073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6441</td>\n",
       "      <td>-0.6509</td>\n",
       "      <td>-0.6613</td>\n",
       "      <td>-0.8689</td>\n",
       "      <td>-0.6466</td>\n",
       "      <td>-0.6354</td>\n",
       "      <td>-0.6855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0602</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>-0.0713</td>\n",
       "      <td>0.0612</td>\n",
       "      <td>-0.0097</td>\n",
       "      <td>-0.0407</td>\n",
       "      <td>-0.0771</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0473</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>-0.0749</td>\n",
       "      <td>-0.1901</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>-0.0332</td>\n",
       "      <td>-0.0797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.6334</td>\n",
       "      <td>0.7670</td>\n",
       "      <td>0.7066</td>\n",
       "      <td>0.6699</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>0.6508</td>\n",
       "      <td>0.6029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6071</td>\n",
       "      <td>0.6860</td>\n",
       "      <td>0.5743</td>\n",
       "      <td>0.4636</td>\n",
       "      <td>0.7041</td>\n",
       "      <td>0.6575</td>\n",
       "      <td>0.6608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.9702</td>\n",
       "      <td>2.7920</td>\n",
       "      <td>2.6905</td>\n",
       "      <td>2.8091</td>\n",
       "      <td>2.9823</td>\n",
       "      <td>2.9342</td>\n",
       "      <td>3.3240</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0983</td>\n",
       "      <td>3.1469</td>\n",
       "      <td>2.9109</td>\n",
       "      <td>2.4942</td>\n",
       "      <td>3.1804</td>\n",
       "      <td>3.0034</td>\n",
       "      <td>2.5107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "count  500.0000  500.0000  500.0000  500.0000  500.0000  500.0000  500.0000   \n",
       "mean     0.0384    0.0715    0.0056   -0.0103   -0.0436   -0.0208   -0.0571   \n",
       "std      1.0153    0.9613    1.0360    1.0230    1.0647    0.9898    1.0000   \n",
       "min     -3.1722   -2.4596   -2.8834   -3.7474   -2.9987   -3.2014   -3.6855   \n",
       "25%     -0.6090   -0.6207   -0.7180   -0.6594   -0.7177   -0.6510   -0.7073   \n",
       "50%      0.0602    0.0560   -0.0713    0.0612   -0.0097   -0.0407   -0.0771   \n",
       "75%      0.6334    0.7670    0.7066    0.6699    0.6616    0.6508    0.6029   \n",
       "max      2.9702    2.7920    2.6905    2.8091    2.9823    2.9342    3.3240   \n",
       "\n",
       "         ...          193       194       195       196       197       198  \\\n",
       "count    ...     500.0000  500.0000  500.0000  500.0000  500.0000  500.0000   \n",
       "mean     ...      -0.0187    0.0087   -0.0356   -0.1940    0.0250    0.0257   \n",
       "std      ...       0.9731    0.9716    1.0075    1.0246    0.9934    0.9940   \n",
       "min      ...      -2.9110   -2.9642   -2.5163   -3.9278   -2.4254   -2.6234   \n",
       "25%      ...      -0.6441   -0.6509   -0.6613   -0.8689   -0.6466   -0.6354   \n",
       "50%      ...      -0.0473    0.0537   -0.0749   -0.1901    0.0185   -0.0332   \n",
       "75%      ...       0.6071    0.6860    0.5743    0.4636    0.7041    0.6575   \n",
       "max      ...       3.0983    3.1469    2.9109    2.4942    3.1804    3.0034   \n",
       "\n",
       "            199  \n",
       "count  500.0000  \n",
       "mean    -0.0036  \n",
       "std      0.9819  \n",
       "min     -2.8690  \n",
       "25%     -0.6855  \n",
       "50%     -0.0797  \n",
       "75%      0.6608  \n",
       "max      2.5107  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga de datos\n",
    "X = pd.read_csv(\"../TP1/X.csv\", index_col=\"index\")\n",
    "y = pd.read_csv(\"../TP1/y.csv\", index_col=\"index\", dtype=int)  # Cargamos los valores booleanos (True y False)\n",
    "                                                        # como números (1 y 0) para facilitar el manejo luego. \n",
    "    \n",
    "X_competencia = pd.read_csv(\"../TP1/X_competencia1.csv\", index_col=\"index\")\n",
    "y_competencia_ejemplo = pd.read_csv(\"../TP1/y_competencia_ejemplo.csv\", index_col=\"index\")\n",
    "display(X)\n",
    "display(y)\n",
    "X.describe()\n",
    "\n",
    "# Descomentar si quieren ver los datos para la competencia:\n",
    "# display(X_competencia) \n",
    "# display(y_competencia_ejemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "### Separación de datos\n",
    "\n",
    "Contarán con una cantidad limitada de datos, por lo cual es importante tomar una buena decisión en el momento de empezar a utilizarlos. En este punto pedimos que evalúen cómo separar sus datos para desarrollo y para evaluación tomando en cuenta la competencia. No consideramos necesario normalizar los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del total de los datos nos quedamos con un 0.2% como held out que no fue utilizado a lo largo del trabajo práctico. A la hora de la separación tuvimos en cuenta la distribución de los datos para que fuese equivalente en ambos grupos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_dev: (400, 200), y_dev: (400, 1) para desarrollo\n",
      "X_eval: (100, 200), y_eval: (100, 1) para evaluación\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################################################\n",
    "\n",
    "X_dev, X_eval, y_dev, y_eval = sklearn.model_selection.train_test_split(X, y, random_state=SEED, test_size=0.2)\n",
    "\n",
    "#########################################################\n",
    "\n",
    "print(\"X_dev: {}, y_dev: {} para desarrollo\".format(X_dev.shape, y_dev.shape))\n",
    "print(\"X_eval: {}, y_eval: {} para evaluación\".format(X_eval.shape, y_eval.shape))\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(np.array(y_dev))  # muestra un histograma para la distribución de y.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "### Construcción de modelos\n",
    "\n",
    "Para este punto, la tarea consiste en construir y evaluar modelos de tipo árbol de decisión, de manera de obtener una estimación realista de la performance de los mismos. \n",
    "\n",
    "1. Entrenar un árbol de decisión con altura máxima 3 y el resto de los hiperparámetros en default. \n",
    "2. Estimar la performance del modelo utilizando K-fold cross validation con K = 5, con las métricas “Accuracy” y “ROC AUC”. Para ello, se pide medir la performance en cada partición tanto sobre el fold de validación como sobre los folds de entrenamiento. Luego, completar la primera tabla.\n",
    "3. Entrenar árboles de decisión para cada una de las siguientes combinaciones y completar la segunda tabla.\n",
    "\n",
    "----\n",
    "\n",
    "**EJERCICIO EXTRA**: Usar la implementación de árboles de decisión que realizaron para la guía de ejercicios de la materia. Adaptarla para que cumpla con la interfaz requerida por sklearn, asegurarse de que funcione con variables continuas y reproducir las tablas anteriores.   \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev_np = np.array(X_dev)\n",
    "y_dev_np = np.array(y_dev).ravel()\n",
    "\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 1 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validación)</th>\n",
       "      <th>AUC ROC (training)</th>\n",
       "      <th>AUC ROC (validación)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Permutación</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8031</td>\n",
       "      <td>0.5875</td>\n",
       "      <td>0.8135</td>\n",
       "      <td>0.5984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.8505</td>\n",
       "      <td>0.6202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8187</td>\n",
       "      <td>0.6125</td>\n",
       "      <td>0.8247</td>\n",
       "      <td>0.6132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8281</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>0.8198</td>\n",
       "      <td>0.7238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8094</td>\n",
       "      <td>0.5750</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.5816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy (training)  Accuracy (validación)  AUC ROC (training)  \\\n",
       "Permutación                                                                   \n",
       "1                         0.8031                 0.5875              0.8135   \n",
       "2                         0.8500                 0.6250              0.8505   \n",
       "3                         0.8187                 0.6125              0.8247   \n",
       "4                         0.8281                 0.7375              0.8198   \n",
       "5                         0.8094                 0.5750              0.7845   \n",
       "\n",
       "             AUC ROC (validación)  \n",
       "Permutación                        \n",
       "1                          0.5984  \n",
       "2                          0.6202  \n",
       "3                          0.6132  \n",
       "4                          0.7238  \n",
       "5                          0.5816  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAEGCAYAAAAAHm2OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XtUVXXaB/Dvw+GuqIhkCCKkHvAgocKQZlr2aulkWuOUlo3ZhLfGzGomnWbeLGd1scs0Y1lppqbZKGlTmpa5Jl+1nErUTDmAoqmgchERQRAFnvcPDnhkcznAARS/n7VcnbP37+z9uNX4nn35PaKqICIiIrLn0tIFEBER0ZWHAYGIiIgMGBCIiIjIgAGBiIiIDBgQiIiIyIABgYiIiAwYEIiIiMiAAYGIiIgMGBCIiIjIwLWldtypUycNCQlpqd0TEV2Vdu3adUpV/Vu6Dmr9WiwghISEICEhoaV2T0R0VRKRoy1dA10beImBiIiIDBgQiIiIyIABgYiIiAxa7B4EIiJyjl27dl3n6uq6GEBv8IsfOa4MwP6SkpK46OjorKorGRCIiK5yrq6ui6+//vpe/v7+uS4uLtrS9dDVoaysTLKzsy0ZGRmLAYyqup5Jk4jo6tfb39//LMMB1YeLi4v6+/vnofzMk3F9M9dDRETO58JwQA1h+3tTbRZgQCAiIiID3oPQSoTM3lDr+iOv3FXnNiI/jKx1/b6H99WrJiJqGSGzN0Q7c3tHXrlrlyPjVqxY0WHChAndd+/endi3b9/zzqyhORQUFMiQIUPM//3vf1MOHTrkvmXLlrZTp049Xd/t9O3bN3zPnj3JtY0ZO3Zst2eeeSYzOjq63sfpxIkTrmPHjg3dvn37wfp+tj54BoGIiJxi1apVHfv161ewfPnyjk25n5KSkibZ7ltvvdVp1KhRua6urjh48KDH6tWrq/19XLx4sdbt1BUOAGD16tVHGxIOAKBLly4lnTt3vvj111+3acjnHcWAQEREjZaXl+eyc+fOtkuXLj3y73//+7IfrH/5y1+uN5vNlrCwMMtjjz0WCAD79+/3uPnmm81hYWEWi8XSKzEx0eOLL77wGTJkSI+Kz02YMCF4/vz5fgAQGBgYOW3atECLxdJryZIlvm+88Uan3r179woLC7Pceeed3fPz810AIC0tzXXYsGHdw8LCLGFhYZbNmze3mTlzZpe5c+deV7Hdxx9/PPBvf/vbdagiPj7e7/777z9jqzkwISGhbXh4uOWFF164bv78+X633357j/79+5tvvvnmsLy8PJcBAwaYLRZLL7PZbPnoo486VGzH29u7LwB88cUXPrGxsWHDhw+/ITQ0NGLUqFGhZWVlAIDY2Niwbdu2eVeMf/zxxwPDwsIsUVFR4Wlpaa4AkJiY6BEVFRVuNpstM2bM6FKxXQC45557zixfvtyv0X9wtWBAICKiRvv444873HbbbXk33nhjsa+vb8n27du9ASA+Pr7dxo0bO+zatSs5JSXFOmfOnAwAePDBB0OnTp2alZKSYk1ISEgODg6u/Ws5AD8/vxKr1Zo0efLk3PHjx+fu378/KSUlxRoWFlY0f/78TgAwderU4EGDBuWnpKRYExMTrf369Ts/bdq0U6tWrfIDgNLSUnz22We+kyZNyrHf9vnz5yUtLc0jLCzsAgC8+OKLx2NiYgqSk5Otc+bMyQKAxMRE788///zQzp07U7y9vcs2bNiQarVak7Zu3Xrg2WefDar44W8vKSnJa8GCBWmpqamJx44d89i8eXPbqmOKiopcBgwYUJCSkmIdMGBAwVtvveUPANOnT+/62GOPZR04cMAaFBR02fEZOHDguR9//NGwLWdiQCAiokaLj4/v+MADD+QCwJgxY06vWLGiIwBs3ry53UMPPXTKx8enDAA6d+5cmpub65KZmek+YcKEMwDg7e2tFetrM2HChNyK17t27fKKjo4OM5vNlrVr1/olJiZ6AsCOHTt8/vSnP2UDgKurK/z8/ErDwsIudOjQoeS7777z+ve//90uIiKi8Prrry+133ZGRoarj49PrdcuBg0adLZz586lQPkcAjNnzgwym82WIUOGmLOystzT09MN9/VFRkae6969+0WTyYSIiIjCQ4cOuVcd4+bmpuPGjcsDgOjo6HNHjx51B4A9e/a0/f3vf38aAOLi4i4LNF26dCnJysoybMuZeJMiERE1SmZmpun777/3SUlJ8Zo+fTpKS0tFRLSsrCy9Pttxc3NT+2/hxcXFYr/ePkRMnjw5dM2aNakDBgwomj9/vt/WrVt9atv2I488cmrx4sWdsrKy3B555JGcquvbtGlTduHChVq/NHt7e1fuf+HChR1zcnJc9+3bl+Th4aGBgYGRRUVFhs97eHhUPn5qMplQUlIiVce4urqqi4tLxetqx1RVWFgoHh4edYaqxuAZBKJWLGT2hlp/ETnDihUrfO+9997TJ06c2Hf8+PF9GRkZPwcFBV3YtGlT2zvvvPPsRx991KniHoHMzEyTr69v2fXXX39hxYoVHQCgqKhI8vPzXbp3716cmprqVVRUJKdOnTJ9++237WraZ2FhoUtwcPDF4uJiWbVqVeU9DwMHDsx/7bXX/IHymxlzcnJMAPC73/3uzJYtW9rv3bu3zZgxY/Kqbs/f37+0tLRUCgsLBQDat29fWlBQYKpp/3l5eaZOnTpd9PDw0PXr1/ucOHHC6d/m+/TpU7Bs2TJfAFiyZMll93Xs37/f02w2Fzl7n/Z4BoGoiroe9wT4yCdd2Rx9LNFZPvnkk45/+tOfMuyXjR49Ovejjz7quHLlymO7d+/27tOnTy83NzcdOnRo3ttvv338o48++mXSpEnd/va3v3Vxc3PTTz755JDFYrlw991354aHh0cEBQUVR0REFNa0z9mzZ5+IjY3t1bFjx5J+/foVVPwwf/fdd49NnDixm9ls7uTi4oK333776NChQ895enrqzTfffLZDhw6lrq7V/+gbPHhw3tdff932nnvuyY+NjS0ymUwaFhZmefDBB0/5+vpedkkiLi7u9IgRI3qYzWbLjTfeWBgaGur0xzrfeuuttPHjx4e+9tprAbfffvvZtm3bVtawefNmn+HDhxuCjjOJastMvhUTE6MJCQktsu/WiPMgXNLYY9GaAgKPResjIrtUNcZ+2d69e49ERUWdaqmargalpaWIiIiwfPLJJ4ciIyOLqxvz7bffer/++uudP/vss1+au77q5Ofnu7Rp06bMxcUFixYt8l29enXH//znP4cAICYmJuzLL79M9ff3L61rO3XZu3dvp6ioqJCqyx06gyAiwwH8E4AJwGJVfaXK+mAAHwLoYBszW1U3Nrbo5tBafigSEVH1du3a5Tl69OieI0aMyK0pHADALbfcUpiQkHC2pKQENZ1laE7fffed9xNPPBGsqmjXrl3psmXLjgDlEyU98cQTmc4IB7Wp8wiIiAnAAgDDAKQD2Cki61TVajfsrwDiVfVdEbEA2AggpAnqJSJqEGecZaOrU3R09Pn09HSHvu3NnDnTcANjSxk+fHhBSkqKteryLl26lPzud78709T7d+QmxVgAqap6WFUvAFgFYHSVMQqg4maS9gBOOK9EIiIiam6OnEMJBJBm9z4dwE1VxjwP4GsReRxAGwBDnVJdHfiNgIiIqGk46zHHBwAsU9UgAL8GsEJEDNsWkckikiAiCdnZ2U7aNRERETmbIwHhOICudu+DbMvsPQogHgBU9b8APAF0qrohVV2kqjGqGuPv79+wiomIiAhnz551mTdvnn9padPcq+jIJYadAHqKSCjKg8E4AA9WGXMMwP8AWCYivVAeEHiKgIioJTzf3qntnvF83jXX7rm+TzGkpKS4jxw5sufBgwcTt23b5r1kyRK/ZcuWpVUdFxgYGJmQkJAUEBBQr5aUK1eubJ+YmOj10ksvZQDlHSV///vfBz/zzDOZJlON8zkBaHh76DqPgKqWiMh0AJtQ/gjjElVNFJG5ABJUdR2ApwG8LyJPovyGxYnaUhMsEBE1Ac4JUTf7ds99+/ZtspvVm+oxRPt2z40xePDgwsGDB9c4yVNDjB8/Pg9A5cRIbm5uWLNmzRFHPmvfHvqOO+445+g+HboHQVU3qqpZVbur6ou2Zc/ZwgFU1aqqA1U1SlX7qOrXjhZARERXv9bW7nnkyJE3rFq1qn3FujFjxoQsXbrUNyUlxT06OjrMYrH0slgsvTZv3tym6nbsfx8ZGRmmgQMH9uzRo0fE2LFju9l/dx46dGj3iIiIXj169Ih4/fXXKy/Lr1mzpp3FYukVFhZmGTBggBkA5s+f7zdhwoRgoPxsRf/+/c1ms9kyYMAA88GDB90rapw4cWLXvn37hgcFBUUuXbrUt2KbDWkPzV4MRETUaK2t3fP9999/Oj4+3rdi3XfffdfuvvvuO9OlS5eS7du3H7BarUmrV68+/OSTTwbXVvPs2bO7DBgwoCA1NTXx3nvvPXPy5MnKng0rV648kpiYmPTTTz9ZFy5c2DkjI8N04sQJ1+nTp4d8+umnh1JSUqyfffbZoarbnDZtWvD48eNzDhw4YB07dmzOtGnTKu8TzMzMdEtISEj+/PPPD86ZMyewYnlD2kO3/FRRRER01YuPj+84Y8aMLOBSu+dBgwYVOtruGeWXp2tVtd3zc889F5ifn286d+6c6dZbb80Dyts9r1mz5hfgUrtnPz+/0op2zydPnnRzpN3zb3/727xZs2Z1LSoqkrVr17aPjY3Nb9u2rebk5Lg8+uij3axWq5eLiwuOHj3qUVvN33//vc+nn36aCgDjxo3LmzJlSuV+582b13nDhg0dbPt3S0xM9MzMzHSNjY3NDw8Pv1BxvKpuc8+ePW2+/PLLQwAwbdq00y+88EJQxbpRo0adMZlMiI6OPp+Tk+NWsbwh7aEZEIiIqFFaY7tnb29v7d+/f/6nn37abvXq1b7jxo07DQAvvvhi5+uuu+7i2rVrfykrK4OXl1eDbgj94osvfLZu3eqTkJCQ7OPjUxYbGxtWXbvo+vL09KwMWvaXMxrSHpqXGIiIqFFaY7tnABg7dmzusmXLOu3cudNnzJgxZ4HyNs8BAQEXTSYT3nnnHb+6HjHs379//rJly/yA8sstZ8+eNQHAmTNnTO3bty/18fEp27Nnj+fevXvbAMBtt9127scff/RJTk52rzheVbfZt2/fc4sXL/YFgIULF3aMiYkpqLUINKw9NM8gEBG1Ng4+lugsrbHdMwDce++9Z6dMmRI6bNiwMxXfzGfOnJk1ZsyY7qtWrfK7/fbb87y8vGr9Vv7KK6+cGDNmzA09evSIiImJKQgICLgAAGPGjMlbtGiR/w033BBxww03nI+KijoHlF8KmD9//pF77723R1lZGfz8/C7u2LHjsscT33vvvWMTJkwI+ec//3m9n59fyfLly4/U9WfUkPbQV3W7Z7Y4voTH4hK2OL6Ex+KS1nIs2O65Ya7Gds/OVFt76JraPfMSAxERtWq7du3y7NatW+SgQYPO1tXu+bbbbjtbUlKvOYyueA1tD81LDERE1Kpdre2enaWh7aF5BoGIiIgMGBCIiIjIgJcYiK5lz7evfX1orZPEEVErxjMIREREZMAzCERErUzkh5FObfe87+F9DW73/MUXX/i88cYbnbds2ZJaMW7MmDEhI0eOzHvkkUdyi4uL5cknn+yyYcMG3zZt2pS6u7vrs88+e+L+++8/a7/t2NjYsKysLDcPD48yNzc3XbRo0ZGbb765CABycnJMcXFxXXft2tVWVRETE1OwePHiND8/v1IA+Pnnnz0ef/zxrkeOHPFs06ZNaUhISPHChQuPde3a9bLHFY4ePeo2ceLEblu2bEndsWOHV1pamvvYsWPrNXfAkSNH3KZOndr1q6++OlzbuFtvvbXH2rVrf+nUqVO9niwAgB9//NFr3rx5ndeuXXukvp+tD55BIKJGSQrvVesvunbYt3t29DNPPvlkl4yMDLfk5OREq9WatH79+tSK2QarWr58+eGUlBTrpEmTsv74xz9W9h8YP358t9DQ0AvHjh3bn5aWtj8kJOTCQw891A0on2L47rvv7jllypTso0eP7rdarUmPPfZYdkZGhuEL8ksvvdT50UcfPQUACQkJ3hs2bKj2GtzFizX3lQoJCblYVzgAgK1bt6Y2JBwAQGxsbNHJkyfdK7o4NhUGBCIiarTa2j3XJD8/3+Xjjz/2X7x48TEvLy8FgK5du5bExcXl1va5wYMHn8vMzHQHyttG79u3r82rr756omL9a6+9duLnn39uk5iY6LFo0aKO/fr1K3jwwQcrzwSMHDky/1e/+tX5qtvdsGGD75gxY/LOnz8vL7/8cpf169f7hoeHW95//33fp556qss999wT2q9fv/Df/OY3oTW1fU5JSXHv2bNnBFDeovmOO+7oPmjQoJ7dunXrPXXq1MpQExgYGHny5EnXlJQU9xtuuCFi3Lhx3Xr06BExcODAngUFBQIAW7du9TabzZbw8HDLlClTgiq2CwAjRow48+GHH/pW/T04EwMCERE1Wk3tnmtjtVo9AgICLnTs2LFeTYTWr1/fbsSIEWcAYO/evZ4Wi6XQfvpkV1dXWCyWwp9++slz//79Xv369atxyuYKycnJ7u3bty/x8vJST09P/fOf/3zi7rvvzk1OTrZOmjQpFwAOHjzouW3btpT169f/4mjbZ6vV6v3ZZ58dTkpKSly3bp1vamqqW9Uxx44d85wxY0ZWampqYvv27UuXL1/uCwBxcXGh77zzztHk5GSryWS6bNrjm2666dyOHTtqbVDVWA7dgyAiwwH8E4AJwGJVfaXK+jcBDLG99QZwnap2cGahRER05aqp3bOIVDuff03LazNhwoQbLl68KIWFhS67d++2NrZme2lpaW4dO3asdQrF4cOHn2nbtq0CwIULF8SRts+33HLL2Yp7IXr06HH+0KFDHj169LjsGkVgYGBxxf0Uffv2LTxy5IjHqVOnTOfOnXMZOnToOQB4+OGHT2/evLny52pAQEBJZmamIWw4U50BQURMABYAGAYgHcBOEVmnqpV/OKr6pN34xwH0bYJaiYjoClRbu+frrruuJC8v77KfNbm5ua7+/v4lFoul+OTJk+6nT592ceQswvLlyw/fcssthVOnTg2aMmVK8Ndff30oKirqvNVq9S4tLYXJVH7rQmlpKaxWq3dUVNT5rKwst23btrWta9ve3t5lxcXFtZ5Vb9OmTWWNjrZ9dnd3rwxCJpNJL168KHWNcaTtc1FRkYunp2e9zrzUlyOXGGIBpKrqYVW9AGAVgNG1jH8AwL+cURwREV35amv33Lt37+LMzEy33bt3ewLAgQMH3JOTk7369+9f5OPjUzZu3LhTkydPDj5//rwA5X0DlixZUuO1dRcXF/z9738//tNPP7XZs2ePZ+/evYsjIiIKZ82aFVAxZtasWQG9e/cu7N27d/GkSZNydu3a1XbVqlWVNxx++eWXbXfu3Olpv93IyMji48ePV970165du9KCgoIaf0bWt+1zfXXq1Km0TZs2Zd98800bAFixYsVl93VYrVaPsLCwerVvri9HLjEEAkize58O4KbqBopINwChAL6pYf1kAJMBIDiYE7AQETUFRx9LdJba2j2PGDGiYOnSpYcfeeSRkOLiYhdXV1ddsGDB0YrT7v/4xz+Oz5w5M9BsNkd4eHiol5dX6Zw5c05Uv6dybdu21WnTpmW+/PLLnePj44+uXLnySFxcXHDXrl17A0C/fv3OrVy58kjF2M8//zx1xowZXWfNmtXV1dVVe/XqVfTuu+8es99mu3btyoKDg4v379/v0bt37+IRI0bkv/766wHh4eGWp59++mTVGurb9rkhFi5ceGTq1KndXFxcMGDAgHwfH5/KFPLNN9+0GzlyZL0ewawvZ8+DMA7AGlWtNkqp6iIAi4Dyds9O3jcREbWAH3744UDVZX/961+zKl7fcccd5+64447k6j7r6emp7733XjrKv3zW6Mcff0yxf//CCy9kVrz29/cv/fzzz2ts0dy3b9/z27dvP1jb9gFg2rRpWYsWLfKbP3/+ic6dO5fu378/yW71ZU9WREZGFh84cKDyUvu77757HADCwsIuHDx4MBEAZsyYkQOgsvmT/VwQx48f3wcAAQEBqBgPAHPnzq38fUVHRxdV7OPZZ5+9HsA5ACgqKpK9e/d6f/DBB5eFHGdzJCAcB9DV7n2QbVl1xgH4Q2OLIiIiam4TJkw4c+rUqStmAsH4+Pj2b7zxRkBpaakEBgYWf/zxx0cAIDU11f3FF1887ubWpPcoOhQQdgLoKSKhKA8G4wA8WHWQiIQD8AXwX6dWSERE1EyeeuqpUy1dQ4VJkyblVjxiaS8yMrI4MjKyuKn3X+dNiqpaAmA6gE0AkgDEq2qiiMwVkVF2Q8cBWKWqvHRARER0lXPoVIqqbgSwscqy56q8f955ZREREVFL4kyKREREZMCAQEREdBVKS0tzfeutt/yaavtXzN2aRETkHEnhvZza7rlXctI11+65vsfI/ve5cuXK9omJiV4vvfRSRtVx3t7efQsLC/fUd/uvvvqqv7e3d9n06dNzACA3N9flscce6/rmm2/W+ngo0PD20DyDQERETtGa2j03xvjx4/OqCweN8cwzz2RXhAMA8PX1LVu/fv0vVfs6VKeh7aEZEIiIqNFaU7tnAIiKigpPSEionI45NjY2bNu2bd5btmzx7tOnT3ivXr0sffv2Dd+7d6+hSdP8+fP9JkyYEAyUd4ns06dPuNlstsyYMaOL/fEaMGCA2WKx9DKbzZaPPvqoshHT22+/7Wc2my1hYWGWe+65JxQAnnrqqS7PPfdcZwDYsWOHV1RUVLjZbLYMGzase3Z2tqmixmnTpgVGRkb2CgkJ6f3VV19V9qBoSHtoBgQiImq01tTuGQB+85vfnF65cmVHoPzSQ1ZWltvgwYMLo6Kizu/cuTM5KSnJOmfOnOPPPPNMUG3bfeyxx4Lj4uKyDxw4YA0ICKj8tu/t7V22YcOGVKvVmrR169YDzz77bFBZWRkSEhI8X3/99YCtW7ceSElJsS5cuNAwW+LEiRNDX3rppfQDBw5YIyIiimbNmlUZPEpKSmTfvn1J8+bNS5s7d27l8oa0h2ZAICKiRouPj+/4wAMP5AKX2j0DNbd1bmi758DAwMg333wz4Omnn86q+xOOq9ruecKECbnr16/3BYDly5f73n333bkAcPr0adOvf/3r7j179ox45plnuh44cMCzpm0CwO7du9tOmjTpNABMmTKl8hJBWVmZzJw5M8hsNluGDBlizsrKck9PT3fdtGlTu7vvvjs3ICCgBAA6d+58WeuCnJwcU35+vumuu+4qAIBJkyblfP/995VnCu67775cALj55pvPpaenV15SaEh7aN6kSEREjdIa2z2HhoZe7NChQ8kPP/zg9emnn3Z87733jgLArFmzAm+99db8zZs3H0pJSXG//fbbw+ratouLiyEMLVy4sGNOTo7rvn37kjw8PDQwMDDSkTbPdfH09FSg/CxKaWlpZWvphrSH5hkEIiJqlNbY7hkoPxPy0ksvXZ+fn2+66aabigDg7NmzpqCgoAsAsHDhwk51HZt+/foVvP/++x0B4P333698JDEvL8/UqVOnix4eHrp+/XqfEydOuAPAnXfeeXb9+vW+GRkZJqA8fNlvz8/Pr7Rdu3alFfcXfPDBB34DBgwoqKuOhrSH5hkEIqJWxtHHEp2lNbZ7BoCHHnoo93//93+Dn3jiicp6Zs2alREXFxc6b968LsOGDTtT17F55513jo0bN+6Gf/zjH9cPHz68cnxcXNzpESNG9DCbzZYbb7yxMDQ09DwAxMTEnH/66adPDho0KNzFxUV79+5dWPXxxKVLl/4ybdq0bjNmzHAJDg4u/te//nXZ+uo0pD20tFTrhJiYGE1ISGjUNkJmb6h1/ZFX7qpzG5EfRta6ft/D++pVU0vhsbiksceiruMAtKJj4Wnou3aZyNDgOvcR/3JJret7JSfVur65tJa/FyKyS1Vj7Jft3bv3SFRU1BXTZOhqtXz58g4JCQne8+fPrzWgXG2Kioqkf//+YQkJCcnVdYDcu3dvp6ioqJCqy3kGgYiICFdeu2dnaWh76FZ3IKgGz7eve4wD3xaJiFqzK6nds7M0tD00AwI5LCm8V63rr5RTyUTXoLKysjKp7m55otqUlZUJgGqfbuBTDEREV7/92dnZ7W3/sydySFlZmWRnZ7cHsL+69Q6dQRCR4QD+CcAEYLGqvlLNmPsBPA9AAexV1drvfiJqKXVdbnHgUgvPptCVpKSkJC4jI2NxRkZGb/CLHzmuDMD+kpKSuOpW1hkQRMQEYAGAYQDSAewUkXWqarUb0xPAnwEMVNVcEbnOKaUTEVGdoqOjswCMauk6qHVxJGnGAkhV1cOqegHAKgCjq4yZBGCBquYCgKo6dQpMIiIial6OBIRAAGl279Nty+yZAZhF5DsR+d52ScJARCaLSIKIJGRnZzesYiIiImpyznqKwRVATwC3AQgCsE1EIlX1slmmVHURgEVA+URJTtp3k+K1ZiIiuhY5cgbhOICudu+DbMvspQNYp6oXVfUXAAdQHhiIiIjoKuTIGYSdAHqKSCjKg8E4AFWfUPgMwAMAlopIJ5RfcjjszEIbhJMDERERNUidZxBUtQTAdACbACQBiFfVRBGZKyIVd81uApAjIlYAWwD8SVVzqt8iERERXekcugdBVTcC2Fhl2XN2rxXAU7ZfRETXJN6zRK0Jp1omIgKcMoEWUWvCGbeIiIjIgAGBiIiIDBgQiIiIyIABgYiIiAwYEIiIiMiAAYGIiIgMGBCIiIjIgAGBiIiIDBgQiIiIyIABgYiIiAwYEIiIiMiAAYGIiIgMGBCIiIjIgAGBiIiIDBwKCCIyXERSRCRVRGZXs36iiGSLyE+2X3HOL5WIiIiai2tdA0TEBGABgGEA0gHsFJF1qmqtMnS1qk5vghqJiIiomTlyBiEWQKqqHlbVCwBWARjdtGURERFRS3IkIAQCSLN7n25bVtUYEflZRNaISFenVEdEREQtwlk3Ka4HEKKqNwLYDODD6gaJyGSzcz7kAAAN1UlEQVQRSRCRhOzsbCftmoiIiJzNkYBwHID9GYEg27JKqpqjqsW2t4sBRFe3IVVdpKoxqhrj7+/fkHqJiIioGTgSEHYC6CkioSLiDmAcgHX2A0QkwO7tKABJziuRiIiImludTzGoaomITAewCYAJwBJVTRSRuQASVHUdgBkiMgpACYDTACY2Yc1ERETUxOoMCACgqhsBbKyy7Dm7138G8GfnlkZEREQthTMpEhERkQEDAhERERkwIBAREZEBAwIREREZMCAQERGRAQMCERERGTAgEBERkQEDAhERERkwIBAREZEBAwIREREZMCAQERGRAQMCERERGTAgEBERkQEDAhERERkwIBAREZEBAwIREREZOBQQRGS4iKSISKqIzK5l3BgRURGJcV6JRERE1NzqDAgiYgKwAMAIABYAD4iIpZpxPgCeAPCDs4skIiKi5uXIGYRYAKmqelhVLwBYBWB0NeP+BmAegPNOrI+IiIhagCMBIRBAmt37dNuySiLSD0BXVd1Q24ZEZLKIJIhIQnZ2dr2LJSIioubR6JsURcQFwN8BPF3XWFVdpKoxqhrj7+/f2F0TERFRE3EkIBwH0NXufZBtWQUfAL0B/J+IHAHQH8A63qhIRER09XIkIOwE0FNEQkXEHcA4AOsqVqpqnqp2UtUQVQ0B8D2AUaqa0CQVExERUZOrMyCoagmA6QA2AUgCEK+qiSIyV0RGNXWBRERE1PxcHRmkqhsBbKyy7Lkaxt7W+LKIiIioJXEmRSIiIjJgQCAiIiIDBgQiIiIyYEAgIiIiAwYEIiIiMmBAICIiIgMGBCIiIjJgQCAiIiIDBgQiIiIyYEAgIiIiAwYEIiIiMmBAICIiIgMGBCIiIjJgQCAiIiIDBgQiIiIycCggiMhwEUkRkVQRmV3N+qkisk9EfhKRb0XE4vxSiYiIqLnUGRBExARgAYARACwAHqgmAHysqpGq2gfAqwD+7vRKiYiIqNk4cgYhFkCqqh5W1QsAVgEYbT9AVc/avW0DQJ1XIhERETU3VwfGBAJIs3ufDuCmqoNE5A8AngLgDuD26jYkIpMBTAaA4ODg+tZKREREzcRpNymq6gJV7Q5gFoC/1jBmkarGqGqMv7+/s3ZNRERETuZIQDgOoKvd+yDbspqsAnBPY4oiIiKiluVIQNgJoKeIhIqIO4BxANbZDxCRnnZv7wJw0HklEhERUXOr8x4EVS0RkekANgEwAViiqokiMhdAgqquAzBdRIYCuAggF8DDTVk0ERERNS1HblKEqm4EsLHKsufsXj/h5LqIiIioBXEmRSIiIjJgQCAiIiIDBgQiIiIyYEAgIiIiAwYEIiIiMmBAICIiIgMGBCIiIjJgQCAiIiIDBgQiIiIyYEAgIiIiAwYEIiIiMmBAICIiIgMGBCIiIjJgQCAiIiIDBgQiIiIycCggiMhwEUkRkVQRmV3N+qdExCoiP4vIf0Skm/NLJSIiouZSZ0AQEROABQBGALAAeEBELFWG7QEQo6o3AlgD4FVnF0pERETNx5EzCLEAUlX1sKpeALAKwGj7Aaq6RVULbW+/BxDk3DKJiIioOTkSEAIBpNm9T7ctq8mjAL5sTFFERETUslyduTEReQhADIBba1g/GcBkAAgODnbmromIiMiJHDmDcBxAV7v3QbZllxGRoQD+AmCUqhZXtyFVXaSqMaoa4+/v35B6iYiIqBk4EhB2AugpIqEi4g5gHIB19gNEpC+AhSgPB1nOL5OIiIiaU50BQVVLAEwHsAlAEoB4VU0UkbkiMso27DUAbQF8IiI/ici6GjZHREREVwGH7kFQ1Y0ANlZZ9pzd66FOrouIiIhaEGdSJCIiIgMGBCIiIjJgQCAiIiIDBgQiIiIyYEAgIiIiAwYEIiIiMmBAICIiIgMGBCIiIjJgQCAiIiIDBgQiIiIyYEAgIiIiAwYEIiIiMmBAICIiIgMGBCIiIjJgQCAiIiIDBgQiIiIycCggiMhwEUkRkVQRmV3N+sEisltESkTkt84vk4iIiJpTnQFBREwAFgAYAcAC4AERsVQZdgzARAAfO7tAIiIian6uDoyJBZCqqocBQERWARgNwFoxQFWP2NaVNUGNRERE1MwcucQQCCDN7n26bVm9ichkEUkQkYTs7OyGbIKIiIiaQbPepKiqi1Q1RlVj/P39m3PXREREVA+OBITjALravQ+yLSMiIqJWypGAsBNATxEJFRF3AOMArGvasoiIiKgl1RkQVLUEwHQAmwAkAYhX1UQRmSsiowBARH4lIukA7gOwUEQSm7JoIiIialqOPMUAVd0IYGOVZc/Zvd6J8ksPRERE1ApwJkUiIiIyYEAgIiIiAwYEIiIiMmBAICIiIgMGBCIiIjJgQCAiIiIDBgQiIiIyYEAgIiIiAwYEIiIiMmBAICIiIgMGBCIiIjJgQCAiIiIDBgQiIiIyYEAgIiIiAwYEIiIiMnAoIIjIcBFJEZFUEZldzXoPEVltW/+DiIQ4u1AiIiJqPnUGBBExAVgAYAQAC4AHRMRSZdijAHJVtQeANwHMc3ahRERE1HwcOYMQCyBVVQ+r6gUAqwCMrjJmNIAPba/XAPgfERHnlUlERETNydWBMYEA0uzepwO4qaYxqloiInkA/ACcsh8kIpMBTLa9LRCRlIYU7SjHEsr+TqhSp72qp0qMO7k6chCPxSV1V1n7cQB4LOzxWFzSTMeimzM2QlQXRwKC06jqIgCLmnOfdRGRBFWNaek6rgQ8FuV4HC7hsbiEx4KuNY5cYjgOoKvd+yDbsmrHiIgrgPYAcpxRIBERETU/RwLCTgA9RSRURNwBjAOwrsqYdQAetr3+LYBvVFWdVyYRERE1pzovMdjuKZgOYBMAE4AlqpooInMBJKjqOgAfAFghIqkATqM8RFwtrqhLHi2Mx6Icj8MlPBaX8FjQNUX4RZ+IiIiq4kyKREREZMCAQERERAYMCERERGTAgEDXPBGJFZFf2V5bROQpEfl1S9d1JRCR5S1dAxG1jGadKImuHCISjvIZMH9Q1QK75cNV9auWq6x5icgclPcZcRWRzSifJXQLgNki0ldVX2zRApuRiFR9fFkADBGRDgCgqqOav6org4jcgvJp5/er6tctXQ9Rc+BTDDYi8oiqLm3pOpqDiMwA8AcASQD6AHhCVT+3rdutqv1asr7mJCL7UH4MPABkAAhS1bMi4oXy8HRjixbYjERkNwArgMUAFOUB4V+wPbasqltbrrrmJSI/qmqs7fUklP97+TeAOwCsV9VXWrI+oubASwyXvNDSBTSjSQCiVfUeALcB+F8RecK27uqYON95SlS1VFULARxS1bMAoKpFAMpatrRmFwNgF4C/AMhT1f8DUKSqW6+lcGDjZvd6MoBhqvoCygPC+JYpiah5XVOXGETk55pWAejcnLW0MJeKywqqekREbgOwRkS64doLCBdExNsWEKIrFopIe1xjAUFVywC8KSKf2P6biWvs/xF2XETEF+VfokRVswFAVc+JSEnLlkbUPK61f/ydAdwJILfKcgGwo/nLaTGZItJHVX8CAFUtEJGRAJYAiGzZ0prdYFUtBip/QFZww6Xpw68pqpoO4D4RuQvA2Zaup4W0R/nZFAGgIhKgqidFpC2uvRBN16hr6h4EEfkAwFJV/baadR+r6oMtUFazE5EglJ9az6hm3UBV/a4FyiK64omIN4DOqvpLS9dC1NSuqYBAREREjuFNikRERGTAgEDUTETEJCJ/EBHPlq6FiKguDAh0xRKRUhH5SUT2i8gntuu/zbn/mQ3dp4jEiMj8KotfB5CkqucbXx0RUdPiPQh0xRKRAlVta3u9EsAuVf27g581qWppI/d/BECMqp5qzHaIiK5GPINAV4vtAHoAgIg8JCI/2s4uLBQRk215gYi8ISJ7AQwQkSMi8rJtXIKI9BORTSJySESm2j5zm4h8UbETEXlbRCbaZpvsAmCLiGyxrXvXtp1EEXnB7jO/EpEdIrLXVpeP/XZFpKOIfCYiP4vI9yJyo2358yKyRET+T0QO2/ZJRHRFYECgK56IuKK8X8I+EekFYCyAgaraB0ApLs1s1wbl0yNH2T3Kesw2bjuAZQB+C6A/6pg5U1XnAzgBYIiqDrEt/ouqxgC4EcCtInKjiLgDWI3y6aqjAAwFUFRlcy8A2GObtvlZAPYNkMJRPjdHLIA5IuIGIqIrwLU2URJdXbxE5Cfb6+0APkD5tLfRAHaKCAB4AciyjSkFsLbKNioaEO0D0FZV8wHki0hxRROierhfRCaj/N9NAAALynsWnFTVnQBQMVWzrbYKtwAYY1v/jYj4iUg727oNtomaikUkC+WTeaXXsy4iIqdjQKArWZHt238lKf/J+6Gq/rma8eerue+g2PbfMrvXFe9dAZTg8jNp1T5hICKhAP4I4Feqmisiy2oaW0/2NZWC/yaJ6ArBSwx0tfkPgN+KyHVA5fX9bo3Y3lEAFhHxsJ1R+B+7dfkAfGyv2wE4ByBPRDqj/JIHAKQACBCRX9nq8bFdErG3HbbLILa+F6cqzjQQEV2p+G2FriqqahWRvwL4WkRcAFxEeSveow3cXpqIxAPYD+AXAHvsVi8C8JWInFDVISKyB0AygDQA39k+f0FExgJ4y9Yiugjl9yHYex7AEluzsEJcoz0eiOjqwscciYiIyICXGIiIiMiAAYGIiIgMGBCIiIjIgAGBiIiIDBgQiIiIyIABgYiIiAwYEIiIiMjg/wEXk3xpiNnxSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies_training, accuracies_validation, aucs_training, aucs_validation = [], [], [], []\n",
    "\n",
    "########################################################\n",
    "# (1) y (2)\n",
    "########################################################\n",
    "for dev_index, eval_index in kf.split(X_dev_np):\n",
    "    X_dev_folds  = X_dev_np[dev_index]\n",
    "    X_eval_folds = X_dev_np[eval_index]\n",
    "    y_dev_folds, y_eval_folds = y_dev_np[dev_index], y_dev_np[eval_index]\n",
    "    \n",
    "    tree = DecisionTreeClassifier(max_depth=3)\n",
    "    tree.fit(X_dev_folds, y_dev_folds)\n",
    "    \n",
    "    prediction_dev = tree.predict(X_dev_folds)\n",
    "    prediction_eval = tree.predict(X_eval_folds)\n",
    "    \n",
    "    accuracies_training.append(accuracy_score(y_dev_folds, prediction_dev))\n",
    "    accuracies_validation.append(accuracy_score(y_eval_folds, prediction_eval))\n",
    "    aucs_training.append(roc_auc_score(y_dev_folds, prediction_dev))\n",
    "    aucs_validation.append(roc_auc_score(y_eval_folds, prediction_eval))\n",
    "    \n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(1,6))\n",
    "df.index.name = \"Permutación\"\n",
    "                  \n",
    "df[\"Accuracy (training)\"] = accuracies_training   \n",
    "df[\"Accuracy (validación)\"] = accuracies_validation  \n",
    "df[\"AUC ROC (training)\"] = aucs_training      \n",
    "df[\"AUC ROC (validación)\"] = aucs_validation    \n",
    "\n",
    "\n",
    "display(HTML(\"<h3> TABLA 1 </h3>\"))\n",
    "display(df)\n",
    "\n",
    "df.plot(kind=\"bar\")\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aclaración**: dividimos el X_dev definido inicialmente resultado de la separación del **held-out** en un set llamado train y otro llamado test para el entrenamiento de los próximos modelos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_dev, y_dev, random_state=SEED, test_size=0.2)\n",
    "\n",
    "X_train_np = np.array(X_train)\n",
    "y_train_np = np.array(y_train).ravel()\n",
    "X_test_np  = np.array(X_test)\n",
    "y_test_np  = np.array(y_test).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 2 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altura máxima</th>\n",
       "      <th>Criterio de evaluación de corte</th>\n",
       "      <th>AUC ROC promedio (training)</th>\n",
       "      <th>AUC ROC promedio (validación)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.8414</td>\n",
       "      <td>0.6927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.6823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Gini</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.7993</td>\n",
       "      <td>0.6562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.9275</td>\n",
       "      <td>0.6354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Altura máxima Criterio de evaluación de corte  AUC ROC promedio (training)  \\\n",
       "0             3                            Gini                       0.8414   \n",
       "1             5                            Gini                       0.9480   \n",
       "2     Inifinito                            Gini                       1.0000   \n",
       "3             3         Ganancia de Información                       0.7993   \n",
       "4             5         Ganancia de Información                       0.9275   \n",
       "5     Inifinito         Ganancia de Información                       1.0000   \n",
       "\n",
       "   AUC ROC promedio (validación)  \n",
       "0                         0.6927  \n",
       "1                         0.6823  \n",
       "2                         0.6562  \n",
       "3                         0.6562  \n",
       "4                         0.6354  \n",
       "5                         0.6250  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################################################\n",
    "# (3)\n",
    "########################################################\n",
    "\n",
    "resultados_training, resultados_validation = [], []\n",
    "\n",
    "for criterio in [\"gini\", \"entropy\"]:\n",
    "     for altura in [3, 5, None]:\n",
    "        tree = DecisionTreeClassifier(max_depth=altura, criterion=criterio, random_state=SEED)\n",
    "        tree.fit(X_train, y_train)\n",
    "        \n",
    "        prediction_dev  = tree.predict(X_train)\n",
    "        prediction_eval = tree.predict(X_test)\n",
    "        \n",
    "        resultados_training.append(roc_auc_score(y_train, prediction_dev))\n",
    "        resultados_validation.append(roc_auc_score(y_test, prediction_eval))\n",
    "\n",
    "df = pd.DataFrame(index=range(0,6))\n",
    "\n",
    "df[\"Altura máxima\"] = [3, 5, \"Inifinito\"] * 2\n",
    "df[\"Criterio de evaluación de corte\"] = [\"Gini\"] * 3 + [\"Ganancia de Información\"] * 3\n",
    "df[\"AUC ROC promedio (training)\"] = resultados_training # reemplazar por resultados_training\n",
    "df[\"AUC ROC promedio (validación)\"] = resultados_validation # reemplazar por resultados_validation\n",
    "\n",
    "   \n",
    "display(HTML(\"<h3> TABLA 2 </h3>\"))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mi Clasificador Árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 1 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validación)</th>\n",
       "      <th>AUC ROC (training)</th>\n",
       "      <th>AUC ROC (validación)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Permutación</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4531</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.4966</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5406</td>\n",
       "      <td>0.5750</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4594</td>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5531</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.5041</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5594</td>\n",
       "      <td>0.4875</td>\n",
       "      <td>0.4972</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy (training)  Accuracy (validación)  AUC ROC (training)  \\\n",
       "Permutación                                                                   \n",
       "1                         0.4531                 0.4375              0.4966   \n",
       "2                         0.5406                 0.5750              0.5005   \n",
       "3                         0.4594                 0.4250              0.5000   \n",
       "4                         0.5531                 0.5375              0.5041   \n",
       "5                         0.5594                 0.4875              0.4972   \n",
       "\n",
       "             AUC ROC (validación)  \n",
       "Permutación                        \n",
       "1                             0.5  \n",
       "2                             0.5  \n",
       "3                             0.5  \n",
       "4                             0.5  \n",
       "5                             0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies_training, accuracies_validation, aucs_training, aucs_validation = [], [], [], []\n",
    "\n",
    "for dev_index, eval_index in kf.split(X_dev_np):\n",
    "    X_dev_folds  = X_dev_np[dev_index]\n",
    "    X_eval_folds = X_dev_np[eval_index]\n",
    "    y_dev_folds, y_eval_folds = y_dev_np[dev_index], y_dev_np[eval_index]\n",
    "    \n",
    "    tree = MiClasificadorArbol(list(X.columns), profundidad_max=3, criterion='gini')\n",
    "    tree.fit(X_dev_folds, y_dev_folds)\n",
    "    \n",
    "    prediction_dev = tree.predict(X_dev_folds)\n",
    "    prediction_eval = tree.predict(X_eval_folds)\n",
    "    \n",
    "    accuracies_training.append(accuracy_score(y_dev_folds, prediction_dev))\n",
    "    accuracies_validation.append(accuracy_score(y_eval_folds, prediction_eval))\n",
    "    aucs_training.append(roc_auc_score(y_dev_folds, prediction_dev))\n",
    "    aucs_validation.append(roc_auc_score(y_eval_folds, prediction_eval))\n",
    "    \n",
    "## Objetivo: accuracies_training, accuracies_validation, aucs_training y aucs_validation asignados\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(1,6))\n",
    "df.index.name = \"Permutación\"\n",
    "                  \n",
    "df[\"Accuracy (training)\"] = accuracies_training   \n",
    "df[\"Accuracy (validación)\"] = accuracies_validation  \n",
    "df[\"AUC ROC (training)\"] = aucs_training      \n",
    "df[\"AUC ROC (validación)\"] = aucs_validation    \n",
    "\n",
    "\n",
    "display(HTML(\"<h3> TABLA 1 </h3>\"))\n",
    "display(df)\n",
    "\n",
    "# Descomentar las siguientes líneas para graficar el resultado\n",
    "df.plot(kind=\"bar\")\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# (EE 3)\n",
    "########################################################\n",
    "\n",
    "resultados_training = []\n",
    "resultados_validation = []\n",
    "\n",
    "for criterio in [\"gini\", \"entropy\"]:\n",
    "    for altura in [3, 5, None]:\n",
    "        tree = MiClasificadorArbol(list(X.columns), profundidad_max=altura, criterion=criterio)\n",
    "        tree.fit(X_train_np, y_train_np)\n",
    "        \n",
    "        prediction_dev  = tree.predict(X_train_np)\n",
    "        prediction_eval = tree.predict(X_test_np)\n",
    "\n",
    "        resultados_training.append(roc_auc_score(y_train, prediction_dev))\n",
    "        resultados_validation.append(roc_auc_score(y_test, prediction_eval))\n",
    "\n",
    "df = pd.DataFrame(index=range(0,6))\n",
    "\n",
    "df[\"Altura máxima\"] = [3, 5, \"Inifinito\"] * 2\n",
    "df[\"Criterio de evaluación de corte\"] = [\"Gini\"] * 3 + [\"Ganancia de Información\"] * 3\n",
    "df[\"AUC ROC promedio (training)\"] = resultados_training # reemplazar por resultados_training\n",
    "df[\"AUC ROC promedio (validación)\"] = resultados_validation # reemplazar por resultados_validation\n",
    "\n",
    "   \n",
    "display(HTML(\"<h3> TABLA 2 </h3>\"))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Comparación de algoritmos\n",
    "\n",
    "\n",
    "Se pide explorar distintas combinaciones de algoritmos de aprendizaje e hiperparámetros, de manera de buscar una performance óptima. Para este ejercicio es necesario que evalúen posibilidades utilizando la técnica de Grid Search. Como métrica de performance, usar siempre el área bajo la curva (AUC ROC) resultante de 5-fold cross-validation. \n",
    "\n",
    "Algoritmos a probar: KNN, árboles de decisión, LDA, Naive Bayes y SVM. Hiperparámetros: Revisar la documentación de cada uno para la búsqueda de combinaciones prometedoras.  \n",
    "\n",
    "Se pide generar un reporte que contenga: \n",
    "\n",
    "1. Una descripción de las distintas combinaciones consideradas y su performance asociada (las que consideren relevantes, con al menos la mejor combinación para cada algoritmo). \n",
    "\n",
    "1. Una breve explicación de los factores que creen que produjeron dicho resultado. \n",
    "\n",
    "En este punto evaluaremos tanto los hiperparámetros elegidos como las conclusiones relacionadas a por qué piensan que ciertos algoritmos funcionan mejor que otros para estos datos. \n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "**EJERCICIO EXTRA**: Utilizar RandomizedSearchCV con rangos de parámetros que contengan a los utilizados en el GridSearch. Analizar si se encontraron mejores combinaciones de parámetros que no hayan sido tenidas en cuenta con el GridSearch y cuál fue la diferencia de tiempo de ejecución. \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_resultados(grid, top=5, algorithm_name=''):\n",
    "    ## Si quieren, pueden utilizar esta función para imprimir las mejores combinaciones de su grid\n",
    "    print(algorithm_name)\n",
    "    print(\"Top {} combinaciones\".format(top))\n",
    "    df = pd.DataFrame(grid.cv_results_[\"params\"])\n",
    "    df[\"mean_score_validation\"] = grid.cv_results_[\"mean_test_score\"]\n",
    "    df[\"mean_score_training\"] = grid.cv_results_[\"mean_train_score\"]\n",
    "    display(df.sort_values(by=\"mean_score_validation\", ascending=False).head(top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = np.array(X_dev)\n",
    "y_np = np.array(y_dev).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighbors Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_knn = {\n",
    "    'n_neighbors': [50, 60, 70, 80, 90], \n",
    "    'algorithm': ['ball_tree', 'kd_tree', 'brute', 'auto']\n",
    "}\n",
    "clf = GridSearchCV(KNeighborsClassifier(weights='uniform'), parameters_knn, cv=5)\n",
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, 10, 'KNeighbors Classifier - Grid Search')\n",
    "\n",
    "parameters_knn = {\n",
    "    'n_neighbors': list(range(50, 90)), \n",
    "    'algorithm': ['ball_tree', 'kd_tree', 'brute', 'auto']\n",
    "}\n",
    "n_iter = 10\n",
    "clf = RandomizedSearchCV(KNeighborsClassifier(weights='uniform'), parameters_knn, cv=5, n_iter=n_iter)\n",
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, n_iter, 'KNeighbors Classifier - Randomized Search')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del total de 8 parametros probamos todas las permutaciones de los siguientes tres para distintos valores:\n",
    "\n",
    "- n_neighbors: número de vecinos utilizado por kneighbors query. Que por default es 5. \n",
    "- weights: es la función de peso que se utiliza en la predicción. Tiene como opciones: uniform (todos los puntos del vecindario pesan lo mismo), distance (los vecinos más cercanos tienen más peso) y callable (función definida por el usuario). \n",
    "- algorithm: es el algoritmo utilizado para computar los vecinos más cercanos. Puede ser: ball_tree, kd_tree, brute o \n",
    "auto. \n",
    "\n",
    "En una primera corrida los valores utilizados para n_neighbors fueron 1, 5, 10 y 50.\n",
    "De las opciones de weights se dejó afuera callable por falta de experiencia.\n",
    "De algorithm se corrieron las opciones ball_tree, kd_tree, brute y auto.\n",
    "\n",
    "Respecto de la performance. Los mejores rendimientos están dados por las combinaciones: auto/brute/kd_tree, 50, uniform. En todas ellas el accuracy promedio sobre los datos de validación es de 0.7625 en relación al accuracy promedio sobre los datos de entrenamiento de 0.78. En todas las otras combinaciones el primer valor o bien baja o bien se mantiene, pero sube el segundo hasta 1. \n",
    "Pareciera que lo que marca la diferencia es el weight. Siempre mejora con uniform mientras que overfittea con distance bajo las mismas combinaciones de los otros parametros. \n",
    "\n",
    "A partir de esos resultados decidimos seguir explorando valores de vecinos mayores a 50. Mientras que para weights seguimos variando en las mismas opciones y algorithm lo dejamos fijo en uniform.\n",
    "\n",
    "Vemos entonces que la mejor combinación de hiperparámetros obtenida corresponde a 70 vecinos con un accuracy promedio para los datos de validación de 0.7725. La cantidad de vecinos representa en el algoritmo la cantidad de elementos que van a votar para clasificar el nuevo valor. \n",
    "\n",
    "Finalmente, se buscó optimizar la búsqueda de los hiperparámetros a través de Randomized Search. Para esto se definió un rango continuo de valores entre los extremos utilizados en la búsqueda anterior. Como resultado se vió que la combinación de hiperparámetros para este modelo es con algorith igual a \"auto\", la cantidad de vecinos 69 y weigths igual a \"uniform\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(LinearDiscriminantAnalysis(), {}, cv=5)\n",
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, 1, 'Linear Discriminant Analysis - Grid Search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo a lo visto en la teórica y a la documentación de sklearn este modelo no presenta hiperparámetros para tunear. Por lo tanto mostramos un único resultado utilizando todas las variables por default. Podemos notar, que está muy cerca de overfittear con los datos de entrenamiento lo que resulta en un mal resultado en los datos de validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_tree = {\n",
    "    'criterion': ('gini', 'entropy'), \n",
    "    'splitter': ('random', 'best'), \n",
    "    'max_depth': list(range(1, 11)) + [50, 100, 150, None]\n",
    "}\n",
    "clf = GridSearchCV(DecisionTreeClassifier(), parameters_tree, cv=5)\n",
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, 10, 'Decision Tree Classifier - Grid Search')\n",
    "\n",
    "parameters_tree = {\n",
    "    'criterion': ('gini', 'entropy'), \n",
    "    'splitter': ('random', 'best'), \n",
    "    'max_depth': list(range(1, 50))\n",
    "}\n",
    "n_iter = 100\n",
    "clf = RandomizedSearchCV(DecisionTreeClassifier(), parameters_tree, n_iter, cv=5)\n",
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, n_iter, 'Decision Tree Classifier - Randomized Search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del total de 13 parámetros probamos todas las permutaciones de los siguientes tres para distintos valores:\n",
    "- criterion: es la función que mide la calidad del split. Las opciones son gini y entropy. \n",
    "- splitter: es la estrategia utilizada para elegir la partición en cada nodo. Puede ser best, para elegir el mejor corte o random que elige el mejor corte al azar. \n",
    "- max_depth: es la profundidad máxima del árbol. Puede ser seteada como int o como None. Si es None, los nodos se expanden hasta que todas las hojas son puras o hasta que contengan menos muestras que min_samples_split.\n",
    "\n",
    "En una primera corrida los valores utilizados para criterion fueron entropy y gini. Para splitter, random y best y para max_depth 3, 50, 100 y None. \n",
    "\n",
    "Respecto de la performance, los mejores rendimientos estuvieron dados por las combinaciones gini/3/random con un accuracy promedio para los datos de validación de 0.69 y con un accuracy promedio para los datos de entrenamiento de 0.77, quedando en segundo lugar la combinación entropy/3/best con un mean_score_validation 0.67 de y con un mean_score_training 0.8. Para todos los demás casos, las cominaciones resultaron en un mean_score_training de 1.00, es decir, cayeron en overfitting. La razón parece ser, sobre todo, los valores altos de max_depth en relación a la cantidad de atributos. \n",
    "\n",
    "Con lo anterior en mente nos dispusimos a variar la profundidad de los árboles. Entonces, para una segunda corrida utilizamos un rango continuo de 1 al 10 y luego valores discretos 50, 100 y None. Podemos ver que los mejores modelos obtenidos tienen siempre una profundidad entre 2 y 4. No es exacto un valor, ya que el hiperparámetro splitter al ser random hace que varíe levemente la performance cada vez que corremos Grid Search.\n",
    "\n",
    "Finalmente, en Randomized Search confirmamos esta última afirmación.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(GaussianNB(), {}, cv=5)\n",
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, 1, 'Gaussian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en LDA, no hay hiperparámetros que ajustar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_svm = {\n",
    "    'C': [1, 0.1, 0.01, 0.0001, 0.00001]\n",
    "}\n",
    "clf = GridSearchCV(LinearSVC(), parameters_svm, cv=5)\n",
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, 10, 'Linear SVM - Grid Search')\n",
    "\n",
    "parameters_svm = {\n",
    "    'C': np.linspace(0.00001,0.01,100)\n",
    "}\n",
    "n_iter = 30\n",
    "clf = RandomizedSearchCV(LinearSVC(), parameters_svm, n_iter, cv=5)\n",
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, n_iter, 'Linear SVM - Randomized Search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del total de 12 parámetros de la función del modelo solo C es hiperparámetro. Ignoramos el hiperparámetro gamma, por no estar en la función de sklearn y kerner, ya que solo trabajaremos con lineal por disposición de la consigna. \n",
    "El parametro C es la proporción de clasificaciones correctas que se va a pedir a un determinado SVM. Valores de C más grandes resultarán en un hiperplano de margen más pequeño y más pequeños al revés. \n",
    "\n",
    "Se varió C a lo largo de distintas iteraciones viendo que los valores menores a uno son los que mejor acomodan los datos. Se utilizó: 1, 0.1, 0.01, 0.0001, 0.00001 en Grid Search.\n",
    "\n",
    "En lo que respecta a la performance, mejora a medida que disminuye C hasta aproximadamente 0.001.\n",
    "\n",
    "A continuación corrimos la búsqueda con Randomized Search para un rango continuo de valores de C entre 0.01 y 0.00001, tomando 100 valores. Lo que vimos es que la performance aumenta a medida que disminuyo el C hasta un límite de 0.0003. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusiones Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distintos sets de datos pueden ser mejor clasificados por unos u otros algoritmos. En este caso, las performances siguen este orden decreciente: KNN, SVM, DecisionTree, LDA, NB. \n",
    "Los últimos dos presentan muchas suposiciones sobre la distribución de los datos. Dado que usamos las distribuciones originales de los datos y no hicimos transformaciones sobre los mismos entonces puede que no se cumplan dichas suposiciones lo que no mejorará al modelo.\n",
    "Por otro lado, los primeros tres son aquellos que no hacen suposiciones probabilísticas sobre los datos sino que se entrenan subdividiendo el espacio en el que se encuentran."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 4: \n",
    "### Diagnóstico Sesgo-Varianza. \n",
    "\n",
    "En este punto, se pide inspeccionar dos de sus mejores modelos encontrados hasta ahora: el mejor modelo de tipo árbol de decisión y el mejor de tipo SVM. Para ello:\n",
    "\n",
    "1. Graficar curvas de complejidad para cada modelo, variando la profundidad en el caso de árboles, y el hiperparámetro C en el caso de SVM. Diagnosticar cómo afectan al sesgo y a la varianza esos dos hiperparámetros.\n",
    "2. Graficar curvas de aprendizaje para cada modelo. En base a estas curvas, sacar conclusiones sobre si los algoritmos parecen haber alcanzado su límite, o bien si aumentar la cantidad de datos debería ayudar.\n",
    "3. Construir un modelo RandomForest con 200 árboles. Explorar para qué sirve el hiperparámetro max_features y cómo afecta a la performance del algoritmo mediante una curva de complejidad. Explicar por qué creen que se dieron los resultados obtenidos. Por último, graficar una curva de aprendizaje sobre los parámetros elegidos para determinar si sería útil o no conseguir más datos (usar  grid search para encontrar una buena combinación de parámetros).  \n",
    "\n",
    "\n",
    "**Atención**: Tener en cuenta que debemos seguir utilizando ROC AUC como métrica para estas curvas.\n",
    "\n",
    "**ver**: http://scikit-learn.org/stable/modules/learning_curve.html#learning-curve\n",
    "\n",
    "----\n",
    "**EJERCICIO EXTRA:** Utilizar RandomizedSearchCV para explorar la performance del algoritmo de Gradient Boosting y comparar con los resultados obtenidos en el punto (c).\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = list(range(1, 11)) + [50, 100, 150, None]\n",
    "auc_roc = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    tree = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    tree.fit(X_train_np, y_train_np)\n",
    "        \n",
    "    prediction_eval = tree.predict(X_test_np)\n",
    "    auc_roc.append(roc_auc_score(y_test_np, prediction_eval))\n",
    "\n",
    "\n",
    "fig = plt.plot(max_depths, auc_roc , marker=\"*\", color=\"blue\")\n",
    "plt.title(\"Curva de complejidad para un modelo de Decision Tree Classifier\")\n",
    "plt.xlabel(\"Profundidad del árbol\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = np.linspace(0.00001, 0.01, 50)\n",
    "auc_roc = []\n",
    "\n",
    "for C in Cs:\n",
    "    svm = LinearSVC(C=C)\n",
    "    svm.fit(X_train_np, y_train_np)\n",
    "        \n",
    "    prediction_eval = svm.predict(X_test_np)\n",
    "    auc_roc.append(roc_auc_score(y_test_np, prediction_eval))\n",
    "\n",
    "\n",
    "fig = plt.plot(Cs, auc_roc, marker=\"*\", color=\"green\")\n",
    "plt.title(\"Curva de complejidad para un modelo de Support Vector Machine\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los errores de predicción pueden ser clasificados en errores de sesgo, errores de varianza y errores irreductibles. Los dos primeros pueden ser mejorados. Para hacerlo, se buscará obtener un método de aprendizaje que logre disminuir al mismo tiempo sesgo y varianza. Se entiende por sesgo las suposiciones que los algoritmos hacen para poder estimar la función target que se desee aprender. Por varianza, la cantidad que varía la estimación al cambiar el set de datos de entrenamiento. Lo que suele ocurrir es que métodos más flexibles en cuanto a las suposiciones, es decir, con menor sesgo, resultan en una mayor varianza y, al revés. Se incurre, así, en un problema de trade-off entre sesgo y varianza. \n",
    "\n",
    "En el caso de los árboles de decisión, este trade-off depende de la profundidad del árbol, es decir, del parámetro max_depth. Un árbol de mayor profundidad hará muy pocas suposiciones sobre los datos y se adaptará muy bien a lo que le sea pasado como entrenamiento, aumentando así la varianza en gran medida al actuar sobre otro set de datos. \n",
    "En caso de los Support Vector Machines, el trade-off depende del parámetro C. Un aumento de este parámetro permite hacer más suposiciones sobre los datos achicando el margen de missclasification del hiperplano. Esto aumenta el sesgo y por consiguiente reduce la varianza. \n",
    "\n",
    "Para los gráficos obtenidos. En caso de árbol de decisión se puede ver que a medida que aumentamos la profundidad del árbol va a disminuir el accuracy. Esto es consistente con lo explicado anteriormente.\n",
    "En caso de SVM se puede ver que hay una tendencia creciente a medida que aumenta el C con estancamientos y máximos locales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Learning Curves (SVM)\"\n",
    "estimator = LinearSVC(C=0.0001)\n",
    "plot_learning_curve(estimator, title, X_dev_np, y_dev_np, ylim=(0.7, 0.95), cv=5, n_jobs=4)\n",
    "\n",
    "title = \"Learning Curves (Decision Tree Classifier)\"\n",
    "estimator = DecisionTreeClassifier(max_depth=3, criterion='entropy', splitter='best')\n",
    "plot_learning_curve(estimator, title, X_dev_np, y_dev_np, (0.6, 1.05), cv=5, n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La curva de aprendizaje muestra el score de validación y de entrenamiento de un estimador variando el número de las muestras de entrenamiento. Sirve para averiguar cuanto se beneficia el modelo de agregar nueva data de entrenamieno y si el estimador sufre más de error de sesgo o de varianza. \n",
    "Si ambos errores estuvieran presentes ambos scores convergerian a un valor demasiado bajo a medida que aumenta el tamaño del set de entrenamiento. En este caso, no se percibirán beneficios al aumentar los datos de entrenamiento. \n",
    "En cambio si el score de entrenamiento es más grande que el de validación para el máximo número de muestras de entrenamiento, agregar más muestras mejorará la generalización.  \n",
    "\n",
    "Nuestros gráficos se encuentran en el segundo caso, ya que la cantidad de datos que tenemos para entrenamiento parecen no ser suficientes para alcanzar la convergencia. Una posible solución sin necesidad de aumentar la cantidad de datos (muchas veces imposible, como en este caso) sería aumentar la cantidad de folds. De esta forma, tendriamos menos datos para la validacion pero más para el entrenamiento, logrando una mejor generalización de los modelos. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_features = [5, 50, 100, 200, 'sqrt', 'log2']\n",
    "auc_roc = []\n",
    "\n",
    "for max_feature in max_features :\n",
    "    random_forest = RandomForestClassifier(n_estimators=200, criterion='entropy', max_depth=3, max_features=max_feature)\n",
    "    auc_roc.append(np.mean(cross_val_score(random_forest, X_train_np, y_train_np, cv=5)))\n",
    "\n",
    "\n",
    "fig = plt.plot(range(len(max_features)), auc_roc, marker=\"*\", color=\"red\")\n",
    "plt.xticks(range(6), ['5', '50', '100', '200', 'sqrt', 'log2'])\n",
    "plt.title(\"Curva de complejidad para un modelo de Random Forest\")\n",
    "plt.xlabel(\"Cantidad máxima de features\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método Random Forest crea una serie de árboles de decisión. Su particularidad reside en que, al momento de hacerlo, cada vez que se considera un split, se elige como candidatos del split de manera random una muestra m de predictores de entre la totalidad del set p. Y de estos m elegidos al azar, el split solo puede elegir uno. Esto hace que una nueva muestra de predictores sea elegida cada vez. \n",
    "\n",
    "max_features determina el número de features considerado al momento de buscar el mejor split. Puede ocurrir: \n",
    "\n",
    "- Si es un int, entonces considera la cantidad max_features de features en cada split. \n",
    "- Si es float, entonces la cantidad max_features es una fracción fraction y se considera int(max_features * n_features) en cada split. \n",
    "- Si es sqrt, entonces max_features=sqrt(n_features)\n",
    "- Si es log2, entonces max_features=log2(n_features)\n",
    "- Si es None, entonces max_features=n_features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que Random Forest no tiene un comportamiento estable en cada ajuste realizado del modelo. Creemos que esto es debido a que tenemos un gran número de features (200) para la cantidad de datos que procesamos (320). Decidimos agregar Cross-Validation para poder quedarnos con un modelo más robusto. Incluso con esas condiciones, seguimos notando que la performance del modelo varía bastante en cada corrida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_rf = {\n",
    "    'criterion': ('gini', 'entropy'), \n",
    "    'max_features':[5, 50, 100, 200, 'auto', 'log2']\n",
    "}\n",
    "clf = GridSearchCV(RandomForestClassifier(n_estimators=200, max_depth=3), parameters_rf, cv=5)\n",
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, 10, 'Random Forest Classifier - Grid Search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Learning Curves (Random Forest)\"\n",
    "estimator = RandomForestClassifier(criterion='entropy', max_depth=3, max_features=50, n_estimators=200)\n",
    "plot_learning_curve(estimator, title, X_dev_np, y_dev_np, ylim=(0.7, 1.05), cv=5, n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de la curva de aprendizaje vemos que mejoraría el modelo si aumentamos la cantidad de datos para el proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_gb = {\n",
    "    'n_estimators': range(10,50), \n",
    "    'max_features':[5, 50, 100, 200, 'auto', 'log2'], \n",
    "    'loss' : ('deviance', 'exponential')\n",
    "}\n",
    "n_iter = 8\n",
    "clf = RandomizedSearchCV(GradientBoostingClassifier(), parameters_gb, n_iter, cv=5)\n",
    "clf.fit(X_np, y_np)\n",
    "top_resultados(clf, n_iter, 'Gradient Boosting Classifier - Randomized Search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que para 200 arboles el modelo overfittea, por lo que en la segunda iteración decidimos agregar para que utilice menos cantidad de árboles.\n",
    "Podemos observar, que no hay grandes mejoras entre utilizar Random Forest o Gradient Boosting como algoritmo de clasificación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competencias\n",
    "\n",
    "La entrega del trabajo estará acompañada de una competencia en la cual deberán poner a prueba su mejor modelo y sobre todo, su capacidad para estimar sus resultados. \n",
    "\n",
    "Su tarea será estimar la performance (AUC ROC) que tendrá su mejor modelo en datos de evaluación (X_competencia). \n",
    "\n",
    "Para ello, deberán predecir las probabilidades de las distintas instancias con su modelo, enviarnos dichas probabilidades junto a una estimación con 4 decimales de cuál será el AUC ROC resultante y calcularemos el resultado real. El grupo que consiga acercarse más al valor real, será el grupo ganador.  \n",
    "\n",
    "Recomendamos no perder de vista esta competencia en el momento de separar los datos en los primeros puntos. \n",
    "\n",
    "Para esto, junto con la entrega del informe, deberán enviar un archivo en formato csv con las columnas “index” y “output” (ver ejemplo de archivo en: [y_competencia_ejemplo.csv](https://github.com/pbrusco/aa-notebooks/blob/master/TP1/y_competencia_ejemplo.csv)) y un valor esperado de AUC ROC. \n",
    "\n",
    "\n",
    "## Entrega\n",
    "- Contarán con un esqueleto en formato Jupyter Notebook en donde tendrán que completar las celdas faltantes (ya sea con explicaciones y gráficos o código). \n",
    "- El notebook final deberá ser entregado en formatos .html e .ipynb. Es necesario que los resultados puedan reproducirse al ejecutar todas las celdas en orden (Kernel - Restart and Run All) utilizando las bibliotecas requeridas en el archivo: requirements.txt del repositorio. \n",
    "- Tienen tiempo hasta las 23:59hs del día miércoles 17/10/2018. La entrega se debe realizar a través del campus virtual y debe contener el informe.\n",
    "- El trabajo deberá elaborarse en grupos de 3 personas.\n",
    "- Se podrán pedir pruebas de integridad y autoría; es decir, verificar que la salida solicitada es fruto del modelo presentado y que el modelo fue construido según lo requerido en este enunciado.\n",
    "- La evaluación será grupal y se basará en la calidad del informe (presentación, claridad, prolijidad); la originalidad, practicidad y coherencia técnica de la solución; la corrección y solidez de las pruebas realizadas.\n",
    "- En el primer parcial se incluirá una pregunta sobre la solución entregada. Esa pregunta no influirá en la nota del parcial, pero sí en la nota individual del TP1.\n",
    "- La participación en la competencia es obligatoria. De todas maneras, el resultado no incidirán en la nota de la materia.\n",
    "- Los ejercicios extra son opcionales para aprobar el TP, pero son obligatorios para promocionar la materia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa",
   "language": "python",
   "name": "aa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
